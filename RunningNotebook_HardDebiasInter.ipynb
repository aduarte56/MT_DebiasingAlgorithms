{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.ProcessingEmbeddings import *\n",
    "from Scripts.HardDebias import *\n",
    "from Scripts.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove-wiki-gigaword-50 embeddings\n",
      "vectors shape: (400000, 50), word2idx length: 400000, vocab length: 400000\n"
     ]
    }
   ],
   "source": [
    "glove=Embeddings('glove-wiki-gigaword-50')\n",
    "#glove300=Embeddings('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=glove.vectors\n",
    "word2idx=glove.word2idx\n",
    "vocab=glove.words\n",
    "dict_vectors = glove.get_word_vector_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(vectors).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:00<00:00, 636322.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of limited vocabulary: 327185\n"
     ]
    }
   ],
   "source": [
    "# Getting a limited vocabulary to debias the embeddings.\n",
    "vocab_cleaned, vectors_cleaned, word2idx_cleaned, dict_vec_cleaned = glove.limit_vocab(vectors, word2idx, vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard-Debias Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender specific vocabulary:\n",
    "gender_specific=[]\n",
    "female_vocab=[]\n",
    "male_vocab=[]\n",
    "with open('./Data/male_word_file.txt') as f:\n",
    "    male_vocab = [line.strip() for line in f]\n",
    "\n",
    "with open('./Data/female_word_file.txt') as f:\n",
    "    for l in f:\n",
    "        female_vocab.append(l.strip())\n",
    "\n",
    "gender_specific=female_vocab+female_vocab\n",
    "\n",
    "with codecs.open('./Data/gender_specific_full.json') as f:\n",
    "    gender_specific.extend(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the definitional sets to calculate afterwards the gender direction. The first 10 gender sets were proposed by Bolukbasi et al. (2016)\n",
    "#Definitional sets for race where proposed by Manzini et al. in Multiclass debiasing of embeddings: https://github.com/TManzini/DebiasMulticlassWordEmbedding/blob/master/Debiasing/data/vocab/race_attributes_optm.json\n",
    "\n",
    "def_sets = {\n",
    "    \"gender\": [\n",
    "        ['she', 'he'], ['herself', 'himself'], [\n",
    "            'her', 'his'], ['daughter', 'son'], ['girl', 'boy'],\n",
    "        ['mother', 'father'], ['woman', 'man'], ['mary', 'john'], ['gal', 'guy'], ['female', 'male'], ['aunt', 'uncle']],\n",
    "\n",
    "    \"race\": [\n",
    "        [\"black\", \"caucasian\", \"asian\", \"hispanic\"],\n",
    "      \t\t[\"african\", \"caucasian\", \"asian\", \"hispanic\"],\n",
    "      \t\t[\"black\", \"white\", \"asian\", \"latino\"],\n",
    "      \t\t[\"africa\", \"europe\", \"asia\", \"mexico\"],\n",
    "      \t\t[\"africa\", \"america\", \"china\", \"latin-america\"],\n",
    "    ]\n",
    "}\n",
    "\n",
    "#Equalizing pairs for gender debiasing were first published by Bolukbasi et al. in https://github.com/tolga-b/debiaswe/blob/master/data/equalize_pairs.json\n",
    "# Equalizing sets for race where defined by Manzini as equal to the defining set (Manzini et al., 2019.p.3)\n",
    "equalizing_lists = {\n",
    "    \"gender\": [\n",
    "        [\"monastery\", \"convent\"], [\"spokesman\", \"spokeswoman\"], [\n",
    "            \"Catholic_priest\", \"nun\"], [\"Dad\", \"Mom\"], [\"Men\", \"Women\"],\n",
    "        [\"councilman\", \"councilwoman\"], [\"grandpa\", \"grandma\"], [\n",
    "            \"grandsons\", \"granddaughters\"], [\"prostate_cancer\", \"ovarian_cancer\"],\n",
    "        [\"testosterone\", \"estrogen\"], [\"uncle\", \"aunt\"], [\n",
    "            \"wives\", \"husbands\"], [\"Father\", \"Mother\"], [\"Grandpa\", \"Grandma\"],\n",
    "        [\"He\", \"She\"], [\"boy\", \"girl\"], [\"boys\", \"girls\"], [\"brother\", \"sister\"], [\n",
    "            \"brothers\", \"sisters\"], [\"businessman\", \"businesswoman\"],\n",
    "        [\"chairman\", \"chairwoman\"], [\"colt\", \"filly\"], [\"congressman\",\n",
    "                                                        \"congresswoman\"], [\"dad\", \"mom\"], [\"dads\", \"moms\"], [\"dudes\", \"gals\"],\n",
    "        [\"ex_girlfriend\", \"ex_boyfriend\"], [\"father\", \"mother\"], [\n",
    "            \"fatherhood\", \"motherhood\"], [\"fathers\", \"mothers\"], [\"fella\", \"granny\"],\n",
    "        [\"fraternity\", \"sorority\"], [\"gelding\", \"mare\"], [\"gentleman\", \"lady\"], [\n",
    "            \"gentlemen\", \"ladies\"], [\"grandfather\", \"grandmother\"],\n",
    "        [\"grandson\", \"granddaughter\"], [\"he\", \"she\"], [\"himself\", \"herself\"], [\n",
    "            \"his\", \"her\"], [\"king\", \"queen\"], [\"kings\", \"queens\"],\n",
    "        [\"male\", \"female\"], [\"males\", \"females\"], [\"man\", \"woman\"], [\n",
    "            \"men\", \"women\"], [\"nephew\", \"niece\"], [\"prince\", \"princess\"],\n",
    "        [\"schoolboy\", \"schoolgirl\"], [\"son\", \"daughter\"], [\"sons\", \"daughters\"], [\"twin_brother\", \"twin_sister\"]]}\n",
    "\n",
    "#Some of the words were taken from the analogies' templates from Cheng and Manzini.\n",
    "#The list is not the same, however, because some of the words were not neutral, but carried some\n",
    "#relation to the social categories.\n",
    "neutral_words = [\"manager\", \"executive\", \"doctor\", \"lawyer\", \"programmer\",\n",
    "                 \"scientist\", \"soldier\", \"supervisor\", \"rancher\", \"janitor\",\n",
    "                 \"firefighter\", \"officer\", \"secretary\", \"nurse\", \"clerk\", \"artist\",\n",
    "                 \"homemaker\", \"dancer\", \"singer\", \"librarian\", \"maid\", \"hairdresser\", \"stylist\",\n",
    "                 \"receptionist\", \"counselor\", \"leader\", \"farmer\",\n",
    "                 \"engineer\", \"laborer\", \"teacher\",\n",
    "                 \"slave\", \"musician\", \"runner\", \"criminal\", \"homeless\",\n",
    "                 \"greedy\", \"cheap\", \"hairy\", \"liberal\",\n",
    "                 \"judgemental\", \"conservative\", \"familial\",\n",
    "                 \"violent\", \"terrorist\", \"dirty\", \"uneducated\", \"educated\"]\n",
    "\n",
    "\n",
    "#However, also the vocabulary without the gendered words from the list can be conceived as neutral, according to Bolukbasi et al.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lists of names for validation\n",
    "#Adapted from Speer's tutorial on racism in sentiment analysis. http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/\n",
    "names_ethnicity = {\n",
    "    # The first two lists are from the Caliskan et al. appendix describing the\n",
    "    # Word Embedding Association Test.\n",
    "    'White': [\n",
    "        'Adam', 'Chip', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Ian', 'Justin',\n",
    "        'Ryan', 'Andrew', 'Fred', 'Jack', 'Matthew', 'Stephen', 'Brad', 'Greg', 'Jed',\n",
    "        'Paul', 'Todd', 'Brandon', 'Hank', 'Jonathan', 'Peter', 'Wilbur', 'Amanda',\n",
    "        'Courtney', 'Heather', 'Melanie', 'Sara', 'Amber', 'Crystal', 'Katie',\n",
    "        'Meredith', 'Shannon', 'Betsy', 'Donna', 'Kristin', 'Nancy', 'Stephanie',\n",
    "        'Bobbie-Sue', 'Ellen', 'Lauren', 'Peggy', 'Sue-Ellen', 'Colleen', 'Emily',\n",
    "        'Megan', 'Rachel', 'Wendy'\n",
    "    ],\n",
    "\n",
    "    'Black': [\n",
    "        'Alonzo', 'Jamel', 'Lerone', 'Percell', 'Theo', 'Alphonse', 'Jerome',\n",
    "        'Leroy', 'Rasaan', 'Torrance', 'Darnell', 'Lamar', 'Lionel', 'Rashaun',\n",
    "        'Tyree', 'Deion', 'Lamont', 'Malik', 'Terrence', 'Tyrone', 'Everol',\n",
    "        'Lavon', 'Marcellus', 'Terryl', 'Wardell', 'Aiesha', 'Lashelle', 'Nichelle',\n",
    "        'Shereen', 'Temeka', 'Ebony', 'Latisha', 'Shaniqua', 'Tameisha', 'Teretha',\n",
    "        'Jasmine', 'Latonya', 'Shanise', 'Tanisha', 'Tia', 'Lakisha', 'Latoya',\n",
    "        'Sharise', 'Tashika', 'Yolanda', 'Lashandra', 'Malika', 'Shavonn',\n",
    "        'Tawanda', 'Yvette'\n",
    "    ],\n",
    "\n",
    "    # This list comes from statistics about common Hispanic-origin names in the US.\n",
    "    'Hispanic': [\n",
    "        'Juan', 'José', 'Miguel', 'Luís', 'Jorge', 'Santiago', 'Matías', 'Sebastián',\n",
    "        'Mateo', 'Nicolás', 'Alejandro', 'Samuel', 'Diego', 'Daniel', 'Tomás',\n",
    "        'Juana', 'Ana', 'Luisa', 'María', 'Elena', 'Sofía', 'Isabella', 'Valentina',\n",
    "        'Camila', 'Valeria', 'Ximena', 'Luciana', 'Mariana', 'Victoria', 'Martina'\n",
    "    ],\n",
    "\n",
    "\n",
    "}\n",
    "#Following Bolukbasi et al. Implementing notebook: https://github.com/tolga-b/debiaswe/blob/master/tutorial_example1.ipynb\n",
    "names = [\"Emily\", \"Aisha\", \"Anne\", \"Keisha\", \"Jill\", \"Tamika\", \"Allison\", \"Lakisha\", \"Laurie\", \"Tanisha\", \"Sarah\",\n",
    "         \"Latoya\", \"Meredith\", \"Kenya\", \"Carrie\", \"Latonya\", \"Kristen\", \"Ebony\", \"Todd\", \"Rasheed\", \"Neil\", \"Tremayne\",\n",
    "         \"Geoffrey\", \"Kareem\", \"Brett\", \"Darnell\", \"Brendan\", \"Tyrone\", \"Greg\", \"Hakim\", \"Matthew\", \"Jamal\", \"Jay\",\n",
    "         \"Leroy\", \"Brad\", \"Jermaine\"]\n",
    "#names_group1 = [names[2 * i] for i in range(len(names) // 2)]\n",
    "#names_group2 = [names[2 * i + 1] for i in range(len(names) // 2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to prepare the def_set_lists for the debiasing\n",
    "def prepare_def_sets_subspace(list_def_sets):\n",
    "  def_sets={i: v for i, v in enumerate(list_def_sets)}\n",
    "  return def_sets\n",
    "\n",
    "def_set_gender=utils.prepare_def_sets_subspace(def_sets[\"gender\"])\n",
    "def_set_race=utils.prepare_def_sets_subspace(def_sets[\"race\"])\n",
    "def_set_joined=utils.prepare_def_sets_subspace(def_sets[\"gender\"]+ def_sets[\"race\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_pairs_from_equalizing_sets(def_sets):\n",
    "    data = {i: v for i, v in enumerate(def_sets)}\n",
    "    #print(data)\n",
    "    pairs = []\n",
    "    for _, values in data.items():\n",
    "\t    #Get all possible combinations of pairs\n",
    "\t    for v1 in values:\n",
    "\t\t    for v2 in values:\n",
    "                           s = set([v1, v2])\n",
    "                           if(len(s) > 1 and not (v1 in pairs and v2 in pairs)):\n",
    "                                pairs.append([v1, v2])\n",
    "                      #     if (v1 in pairs or v2 in pairs):\n",
    "                       #          print(v1,v2)\n",
    "\t#Remove duplicates\n",
    "    pairs.sort()\n",
    "    cleaned_pairs=list(k for k, _ in itertools.groupby(pairs))\n",
    "    return cleaned_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "\n",
    "def get_pairs(p1, p2):\n",
    "    pairs = set()\n",
    "    for v1, v2 in product(p1, p2):\n",
    "        for val1, val2 in product(v1, v2):\n",
    "            pairs.add((val1, val2))\n",
    "    return list(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalizing_lists['race']=get_pairs_from_equalizing_sets(def_sets['race'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalizing_lists['intersection']=get_pairs(def_sets['gender'], def_sets['race'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deb_vect_gender, deb_vocab_gender, deb_word2idx_gender,deb_dict_gender = hard_debias(vectors,\n",
    "                             dict_vectors, \n",
    "                             word2idx_cleaned,\n",
    "                             vocab_cleaned, \n",
    "                             equalizing_lists['gender'], \n",
    "                             def_set_gender,\n",
    "                             1,\n",
    "                             normalize_dir=False,\n",
    "                             normalize=None,\n",
    "                             centralizing=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deb_vect_joined, deb_vocab_joined, deb_word2idx_joined, deb_dict_joined = hard_debias(vectors,\n",
    "                                                                            dict_vectors,\n",
    "                                                                              word2idx_cleaned,\n",
    "                                                                              vocab_cleaned,\n",
    "                                                                              equalizing_lists['intersection'],\n",
    "                                                                              def_set_joined,\n",
    "                                                                              1,\n",
    "                                                                              normalize_dir=False,\n",
    "                                                                              normalize=None,\n",
    "                                                                              centralizing=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Visualization import *\n",
    "from Scripts.Evaluation import *\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender Bias Pre-Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute the gender bias, we need to get the embeddings of \"he\" and \"she\"\n",
    "he_embed = dict_vectors['he']\n",
    "she_embed = dict_vectors['she']\n",
    "\n",
    "# Using the gender bias function to compute the bias of all the words in the limited dataset\n",
    "#We create a dictionary with the word as key and the bias as value\n",
    "gender_bias_original = compute_gender_simple_bias(dict_vec_cleaned, he_embed, she_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_direction = identify_bias_subspace(\n",
    "    dict_vectors, def_set_gender, 1, centralizing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_original2 = compute_direct_bias(\n",
    "    dict_vectors, vocab_cleaned, gender_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_average_bias(deb_dict_gender, neutral_words, gender_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_original2 = compute_direct_bias(\n",
    "    deb_dict_gender, neutral_words, gender_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_after_debiasing=compute_gender_simple_bias(deb_dict_gender, he_embed, she_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations = ['assistant','secretary','data scientist', 'scientist', 'politician','janitor', 'hairdresser','teacher', 'bartender','midwife','doctor','ballerina','dancer','pediatrician','surgeon', 'physician', 'shopkeeper',  'nurse', 'interior designer', 'architect', 'maid', 'housekeeper', 'soprano', 'baritone', 'servant',  'vocalists', 'guitarists','carpenter','clerk','manager','supervisor','driver','software developer','lawyer','pitcher', 'bookkeeper', 'infielder', 'receptionist', 'investigator', 'pundit', 'chancellor', 'maestro','lecturer','salesperson','homemaker', 'receptionist','librarian', 'nanny', 'bookkeeper', 'stylist','housekeeper','guidance counselor','skipper', 'protege','philosopher','captain', 'architect', 'financier', 'warrior', 'broadcaster', 'magician', 'figher','pilot', 'boss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_df=get_bias_score_df_from_list(gender_bias_original,gender_bias_after_debiasing, occupations,vocab_cleaned,deb_vocab_gender)\n",
    "plot_bias_bar(bias_df, \"Gender bias on occupations (original vs debiased)\", \"Occupations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_w2i, c_vocab, female_words, male_words, y_true=getting_biased_words(gender_bias_original, def_sets['gender'], 1000, word2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendered_vectors=utils.extract_vectors(male_words + female_words, vectors_cleaned, word2idx_cleaned)\n",
    "cluster_and_visualize(male_words + female_words,\n",
    "                      gendered_vectors, 'GloVe_original', y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendered_debiased_vectors = utils.extract_vectors(\n",
    "    male_words + female_words, deb_vect_gender, deb_word2idx_gender)\n",
    "\n",
    "cluster_and_visualize(male_words + female_words, gendered_debiased_vectors,\n",
    "                      'Debiased_GloVe', y_true)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Random Words: bias scores and neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "#set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "#choosing random words from the vocabulary\n",
    "random_words = np.random.choice(vocab_cleaned[:10000], size=50)\n",
    "\n",
    "#setting parameters for the gensim method \"most_similar\"\n",
    "topn = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gensim's .most_similar() method finds the top-N most similar words to a given word.\n",
    "#See documentation: https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.most_similar.html\n",
    "glove.model.most_similar(random_words[0], topn=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_original = create_KeyedVectors(vectors_cleaned, vocab_cleaned, 50)\n",
    "model_original.most_similar(random_words[0], topn=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "#Function to find the top-k most similar words to a given word using the cosine similarity\n",
    "def topK(word, dict_vect, vocab, vectors, w2i, k=10):\n",
    "    k_neigh ={}\n",
    "    list_neigh = []\n",
    "    # extract the word vector for word w\n",
    "    idx = w2i[word]\n",
    "    chosen_vec = dict_vect[word]\n",
    "    \n",
    "    # compute cosine similarity between chosen_vec and all other words. Store in similarities list\n",
    "    similarities = np.zeros(len(vocab))\n",
    "    for i in range(len(vocab)):\n",
    "        similarities[i] = cosine_similarity(chosen_vec, vectors[i])\n",
    "    #similarities =[cosine_similarity(vectors.dot(chosen_vec)\n",
    "    # sort similarities by descending order\n",
    "    sorted_similarities = (similarities.argsort())[::-1]\n",
    "\n",
    "    # choose topK\n",
    "    best = sorted_similarities[:(k+1)]\n",
    "\n",
    "    #create a list with the word and similarity score for each of the topK words\n",
    "    k_neig_similarities = [(vocab[i], similarities[i]) for i in best if i!=idx]\n",
    "    k_neigh[word]= k_neig_similarities\n",
    "    list_neigh=[vocab[i] for i in best if i != idx]\n",
    "    return k_neigh, list_neigh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK(random_words[0], dict_vec_cleaned, vocab_cleaned, vectors_cleaned, word2idx_cleaned, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a dictionary with all the k-nearest neighbors for each word in the list\n",
    "def get_k_nearest_neighbors(list_words, dict_vect, vocab, vectors, w2i, k=10):\n",
    "    k_neigh ={}\n",
    "    for w in tqdm(list_words):\n",
    "        dict_neigh, _ = topK(w, dict_vect, vocab, vectors, w2i, k)\n",
    "        k_neigh.update(dict_neigh)\n",
    "    return k_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neigh= get_k_nearest_neighbors(random_words, dict_vec_cleaned, vocab_cleaned, vectors_cleaned, word2idx_cleaned, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of the neighbors for each word of the dictionary k_neigh\n",
    "def get_list_neighbors(k_neigh):\n",
    "    list_neigh = []\n",
    "    for w in k_neigh.keys():\n",
    "        list_neigh.append([i[0] for i in k_neigh[w]])\n",
    "    return list_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_neigh = get_list_neighbors(k_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_original_networks(list_words, list_neigh, dict_vect_debiased, vocab_debiased, vectors_debiased, w2i_debiased, neighbours_num=50):\n",
    "\n",
    "    scores = []\n",
    "    for idx,word in tqdm(enumerate(list_words)):\n",
    "\n",
    "        _, top = topK(word, dict_vect_debiased, vocab_debiased, vectors_debiased, w2i_debiased,\n",
    "                   k=neighbours_num)\n",
    "\n",
    "        count = 0\n",
    "        \n",
    "        for t in top:\n",
    "            if t in list_neigh[idx]:\n",
    "                print(t)\n",
    "                count += 1\n",
    "            \n",
    "\n",
    "        scores.append([word, count, count/neighbours_num])\n",
    "        print(top)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing bits and pieces\n",
    "_, top = topK(random_words[0], deb_dict_gender, deb_vocab_gender, deb_vect_gender, deb_word2idx_gender,\n",
    "                   k=50)\n",
    "_, original_top = topK(random_words[0], dict_vec_cleaned, vocab_cleaned, vectors_cleaned, word2idx_cleaned,\n",
    "                       k=50)\n",
    "\n",
    "count = 0\n",
    "for t in top:\n",
    "    if t in original_top:\n",
    "        print(t)\n",
    "        count += 1\n",
    "    freq = count/50\n",
    "freq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neig_freq=get_frequency_original_networks(\n",
    "    random_words, list_neigh, deb_dict_gender, deb_vocab_gender, deb_vect_gender, deb_word2idx_gender, neighbours_num=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(neig_freq, columns=['word', 'previous_neighbours', 'freq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px\n",
    "#plot the frequency of the original neighbours in the debiased network in a horizontal bar chart\n",
    "\n",
    "fig = px.bar(df, x='word', y='freq', title='Proportion of original 50 neighbours in the debiased network',\n",
    "             labels={'freq':'Proportion', 'word':'Word'},\n",
    "             height=500, width=1000)\n",
    "#update the layout of the plot: update the y axis to be between 0 and 0.5 and the x axis to include all ticks\n",
    "fig.update_layout(yaxis=dict(range=[0, 0.5]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the neighbors of debiased vectors the Gensim way\n",
    "gender_debiased = create_KeyedVectors(deb_vect_gender, deb_vocab_gender, 50)\n",
    "finding_neighbors_before_after(random_words, model_original, gender_debiased, topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neigh= get_k_nearest_neighbors(random_words, deb_dict_gender, deb_vocab_gender, deb_vect_gender, deb_word2idx_gender, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "#This approach was inspired by the following blog post:https://towardsdatascience.com/google-news-and-leo-tolstoy-visualizing-word2vec-word-embeddings-with-t-sne-11558d8bd4d\n",
    "keys = random_words\n",
    "embedding_clusters, db_embedding_clusters, word_clusters = get_embeddings_neighbors(\n",
    "    keys, model_original, gender_debiased, 50)\n",
    "\n",
    "n, m, k = embedding_clusters.shape\n",
    "tsne_model_en_2d = TSNE(perplexity=2, n_components=2,\n",
    "                        init='pca', n_iter=3500, random_state=42)\n",
    "embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(\n",
    "    embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "db_embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(\n",
    "    db_embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot_similar_words('Similar words before Debiasing',\n",
    "                        keys, embeddings_en_2d, word_clusters, 0.7)\n",
    "tsne_plot_similar_words('Similar words after Debiasing',\n",
    "                        keys, db_embeddings_en_2d, word_clusters, 0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tuples of biases and counts of masculine/feminine NN for each word (for bias-by-neighbors)\n",
    "\n",
    "def bias_by_neighbors(dict_vect, vocab, vectors, w2i, neighbours_num=100):\n",
    "\n",
    "    tuples = []\n",
    "    for word in tqdm(vocab):\n",
    "\n",
    "        top = topK(word, dict_vect, vocab, vectors, w2i,\n",
    "                   k=neighbours_num+5)\n",
    "\n",
    "        m = 0\n",
    "        f = 0\n",
    "        for t in top:\n",
    "            if gender_bias_original[t] > 0:\n",
    "                m += 1\n",
    "            else:\n",
    "                f += 1\n",
    "\n",
    "        tuples.append(\n",
    "            (word, gender_bias_original[word], gender_bias_after_debiasing[word], m, f))\n",
    "\n",
    "    return tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_by_neighbors(dict_vec_cleaned, vocab_cleaned, vectors_cleaned, word2idx_cleaned, neighbours_num=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendered_names = [\"ruth\", \"charlotte\", \"abigail\", \"sophie\", \"nichole\", \"emma\", \"olivia\", \"ava\", \"isabella\", \"sophia\", \"charlotte\", \"mia\", \"amelia\"]\n",
    "                 # \"james\", \"john\", \"robert\", \"michael\", \"william\", \"david\", \"richard\", \"joseph\", \"thomas\", \"ariel\", \"mike\", \"nurse\", \"secretary\", \"nursery\"]\n",
    "#words_chosen = [\"miss\", \"mrs\", \"mr\", \"john\", \"rachel\",\n",
    "# \"wife\", \"mom\", \"family\", \"father\", \"lady\", \"he\", \"she\"]\n",
    "\n",
    "gendered_words_before_and_after=finding_neighbors_before_after(gendered_names, model_original, model_debiased, topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys2=gendered_names\n",
    "embedding_clusters, db_embedding_clusters, word_clusters = get_embeddings_neighbors(keys2, model_original, model_debiased, topn)\n",
    "\n",
    "n, m, k = embedding_clusters.shape\n",
    "tsne_model_en_2d = TSNE(perplexity=2, n_components=2,\n",
    "                        init='pca', n_iter=3500, random_state=32)\n",
    "embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(\n",
    "    embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "db_embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(\n",
    "    db_embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "\n",
    "\n",
    "tsne_plot_similar_words('Similar words before Debiasing', keys2, embeddings_en_2d, word_clusters, 0.7)\n",
    "tsne_plot_similar_words('Similar words after Debiasing',\n",
    "                        keys2, db_embeddings_en_2d, word_clusters, 0.7)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [[\"he\", \"she\"],\n",
    "            [\"his\", \"hers\"],\n",
    "            [\"son\", \"daughter\"],\n",
    "            [\"father\", \"mother\"],\n",
    "            [\"male\", \"female\"],\n",
    "            [\"boy\", \"girl\"],\n",
    "            [\"uncle\", \"aunt\"]]\n",
    "\n",
    "Attribtutes = [[\"manager\", \"executive\", \"doctor\", \"lawyer\", \"programmer\", \"scientist\",\n",
    "                \"soldier\", \"supervisor\", \"rancher\", \"janitor\", \"firefighter\", \"officer\"], [\"secretary\", \"nurse\", \"clerk\", \"artist\", \"homemaker\", \"dancer\", \"singer\", \"librarian\", \"maid\", \"hairdresser\", \"stylist\", \"receptionist\", \"counselor\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiasedMAC, debiasedDistribution=multiclass_evaluation_MAC(\n",
    "    debiased_dict, targets, Attribtutes)\n",
    "\n",
    "originalMAC,originalDistribution = multiclass_evaluation_MAC(\n",
    "    dict_vec_cleaned, targets, Attribtutes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel, spearmanr\n",
    "statistics, pvalue = ttest_rel(originalDistribution, debiasedDistribution)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias by neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_w2i, c_vocab, female_words, male_words, y_true=getting_biased_words(\n",
    "    gender_bias_original, def_sets['gender'], 1000, word2idx_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_words=female_words+male_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "k_neighbors=finding_neighbors_before_after(\n",
    "    biased_words, model_original, model_debiased, topn=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take k_neighbors dictionary and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_bias_by_clustering(model_original, model_debiased, biased_words, 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deb_vect_race, deb_vocab_race, deb_word2idx_race, deb_dict_race = hard_debias(vectors,\n",
    "                                                                              dict_vectors,\n",
    "                                                                              word2idx_cleaned,\n",
    "                                                                              vocab_cleaned,\n",
    "                                                                              equalizing_lists['race'],\n",
    "                                                                              def_set_race,\n",
    "                                                                              1,\n",
    "                                                                              normalize_dir=False,\n",
    "                                                                              normalize=None,\n",
    "                                                                              centralizing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neig_freq_race= get_frequency_original_networks(\n",
    "    random_words, list_neigh, deb_dict_race, deb_vocab_race, deb_vect_race, deb_word2idx_race, neighbours_num=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(neig_freq_race, columns=['word', 'previous_neighbours', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding race Debiased Words.\n",
    "race_debiased = create_KeyedVectors(deb_vect_race, deb_vocab_race, 50)\n",
    "finding_neighbors_before_after(random_words, model_original, race_debiased, topn=3)\n",
    "joined_debiased = create_KeyedVectors(deb_vect_joined, deb_vocab_joined, 50)\n",
    "finding_neighbors_before_after(\n",
    "    random_words, model_original, joined_debiased, topn=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Embeddings on a txt file.\n",
    "- And loading them as a Gensim model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the debiased vectors and vocab to a text file\n",
    "glove.save_in_word2vec_format(\n",
    "    debiased_vectors, debiased_vocab, \"./Data/vecs.50.cleaned.txt\")\n",
    "\n",
    "#Loading the vectors into a KeyedVectors object 'model_cleaned' that we can use to find the most similar words to a given word\n",
    "model_cleaned, _, _ = load_word_vectors(\n",
    "    fname=\"./Data/vecs.50.cleaned.txt\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
