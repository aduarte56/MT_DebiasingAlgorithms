{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required scripts\n",
    "from Scripts.ProcessingEmbeddings import *\n",
    "import Scripts.utils as utils\n",
    "from Scripts.HardDebias import *\n",
    "\n",
    "#Importing the required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an embeddings object: 400k words, 50 dimensions\n",
    "glove=Embeddings('Data/glove-wiki-gigaword-300.txt', gensim=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the embeddings object, get the vectors, the word2idx dictionary, the vocab list, and the dict_vectors dictionary\n",
    "# Because the gensim embeddings carry no information on the file, we need to use the built-in function from gensim to get the vocab in descending frequency.\n",
    "glove.model.sort_by_descending_frequency()\n",
    "vectors = glove.vectors\n",
    "word2idx = glove.word2idx\n",
    "vocab = glove.words\n",
    "dict_vectors = glove.get_word_vector_dict()\n",
    "\n",
    "#print the first 20 words in the vocab\n",
    "print(vocab[:20])\n",
    "\n",
    "#Print the shape of the vectors\n",
    "print(\"vectors shape\", vectors.shape)\n",
    "\n",
    "#Print a boolean to check if there are any NaNs in the vectors\n",
    "print(\"Missing values in vectors?\", np.isnan(vectors).any())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing puntuation and numbers from the embeddings\n",
    "vocab_cleaned, vectors_cleaned, word2idx_cleaned, dict_vec_cleaned = glove.limit_vocab(vectors, word2idx, vocab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Hard-Debias Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the definitional sets to calculate afterwards the gender direction. The first 10 gender sets were proposed by Bolukbasi et al. (2016)\n",
    "#Definitional sets for race where proposed by Manzini et al. in Multiclass debiasing of embeddings: https://github.com/TManzini/DebiasMulticlassWordEmbedding/blob/master/Debiasing/data/vocab/race_attributes_optm.json\n",
    "\n",
    "def_sets = {\n",
    "    \"gender\": [\n",
    "        ['she', 'he'], ['herself', 'himself'], \n",
    "        ['her', 'his'], ['daughter', 'son'], ['girl', 'boy'],\n",
    "        ['mother', 'father'], ['woman', 'man'], ['mary', 'john'],\n",
    "        ['gal', 'guy'], ['female', 'male'], ['aunt', 'uncle']],\n",
    "\n",
    "    \"race\": [\n",
    "        [\"black\", \"caucasian\", \"asian\", \"hispanic\"],\n",
    "      \t\t[\"african\", \"caucasian\", \"asian\", \"hispanic\"],\n",
    "      \t\t[\"black\", \"white\", \"asian\", \"latino\"],\n",
    "      \t\t[\"africa\", \"europe\", \"asia\", \"mexico\"],\n",
    "      \t\t[\"africa\", \"america\", \"china\", \"latin-america\"],\n",
    "    ]\n",
    "}\n",
    "\n",
    "#Equalizing pairs for gender debiasing were first published by Bolukbasi et al. in https://github.com/tolga-b/debiaswe/blob/master/data/equalize_pairs.json\n",
    "# Equalizing sets for race where defined by Manzini as equal to the defining set (Manzini et al., 2019.p.3)\n",
    "equalizing_lists = {\n",
    "    \"gender\": [\n",
    "        [\"monastery\", \"convent\"], [\"spokesman\", \"spokeswoman\"], \n",
    "        [\"Catholic_priest\", \"nun\"], [\"Dad\", \"Mom\"], [\"Men\", \"Women\"],\n",
    "        [\"councilman\", \"councilwoman\"], [\"grandpa\", \"grandma\"], \n",
    "        [\"grandsons\", \"granddaughters\"], [\"prostate_cancer\", \"ovarian_cancer\"],\n",
    "        [\"testosterone\", \"estrogen\"], [\"uncle\", \"aunt\"], \n",
    "        [\"wives\", \"husbands\"], [\"Father\", \"Mother\"], [\"Grandpa\", \"Grandma\"],\n",
    "        [\"He\", \"She\"], [\"boy\", \"girl\"], [\"boys\", \"girls\"], [\"brother\", \"sister\"], \n",
    "        [\"brothers\", \"sisters\"], [\"businessman\", \"businesswoman\"],\n",
    "        [\"chairman\", \"chairwoman\"], [\"colt\", \"filly\"], [\"congressman\",\"congresswoman\"], \n",
    "        [\"dad\", \"mom\"], [\"dads\", \"moms\"], [\"dudes\", \"gals\"],\n",
    "        [\"ex_girlfriend\", \"ex_boyfriend\"], [\"father\", \"mother\"],\n",
    "        [\"fatherhood\", \"motherhood\"], [\"fathers\", \"mothers\"], [\"fella\", \"granny\"],\n",
    "        [\"fraternity\", \"sorority\"], [\"gelding\", \"mare\"], [\"gentleman\", \"lady\"], \n",
    "        [\"gentlemen\", \"ladies\"], [\"grandfather\", \"grandmother\"],\n",
    "        [\"grandson\", \"granddaughter\"], [\"he\", \"she\"], [\"himself\", \"herself\"], \n",
    "        [\"his\", \"her\"], [\"king\", \"queen\"], [\"kings\", \"queens\"],\n",
    "        [\"male\", \"female\"], [\"males\", \"females\"], [\"man\", \"woman\"],\n",
    "        [\"men\", \"women\"], [\"nephew\", \"niece\"], [\"prince\", \"princess\"],\n",
    "        [\"schoolboy\", \"schoolgirl\"], [\"son\", \"daughter\"], [\"sons\", \"daughters\"], \n",
    "        [\"twin_brother\", \"twin_sister\"]]}\n",
    "\n",
    "#Words taken from Wang et al. to enrich the equalizing pairs\n",
    "female_vocab = ['countrywoman',  'witches',  'maidservant',  'mothers',  'diva',  'actress',  'spinster',  'mama',  'duchesses',  'countrywomen',  'hostesses',  'suitors',  'menopause',  'clitoris',  'princess',  'governesses',  'abbess',  'women',  'widow',  'ladies',  'sorceresses',  'madam',  'brides',  'baroness',  'niece',  'widows',  'lady',  'sister',  'brides',  'nun',  'obstetrics',  'her',  'marchioness',  'princesses',  'empresses',  'mare',  'chairwoman',  'convent',  'priestesses',  'girlhood',  'ladies',  'queen',  'gals',  'mommies',  'maid',  'spokeswoman',  'seamstress',  'cowgirls',  'chick',  'spinsters',  'empress',  'mommy',  'gals',  'enchantress',  'gal',  'motherhood',  'estrogen',  'godmother',  'strongwoman',  'goddess',  'matriarch',  'aunt',  'chairwomen',  'maam',\n",
    "                'sisterhood',  'hostess',  'estradiol',  'wife',  'mom',  'stewardess',  'females',  'spokeswomen',  'ma',  'belle',  'minx',  'maiden',  'witch',  'miss',  'nieces',  'mothered',  'cow',  'belles',  'granddaughter',  'fiancees',  'stepmothers',  'grandmothers',  'schoolgirl',  'hen',  'granddaughters',  'bachelorette',  'camerawoman',  'moms',  'her',  'mistress',  'lass',  'policewoman',  'nun',  'actresses',  'saleswomen',  'girlfriend',  'councilwoman',  'lady',  'stateswoman',  'maternal',  'lass',  'landlady',  'ladies',  'wenches',  'sorority',  'duchess',  'ballerina',  'chicks',  'fiancee',  'fillies',  'wives',  'she',  'businesswoman',  'masseuses',  'heroine',  'doe',  'girlfriends',  'queens',  'sisters',  'stepmother',  'daughter',  'cowgirl',  'daughters',  'soprano',\n",
    "                'saleswoman',  'mistress',  'nuns',  'headmistresses',  'lasses',  'congresswoman',  'housewife',  'priestess',  'abbesses',  'toque',  'sororities',  'stewardesses',  'filly',  'czarina',  'stepdaughters',  'herself',  'girls',  'lionesses',  'lady',  'vagina',  'hers',  'masseuse',  'cows',  'aunts',  'wench',  'toques',  'wife',  'lioness',  'sorceress',  'mother',  'lesbians',  'female',  'waitresses',  'ovum',  'ovary',  'stepdaughter',  'businesswomen',  'heiress',  'waitress',  'headmistress',  'woman',  'governess',  'bride',  'grandma',  'bride',  'gal',  'lesbian',  'ladies',  'girl',  'grandmother',  'mare',  'hens',  'nuns',  'maidservants',  'heroines']\n",
    "male_vocab = ['countryman',  'wizards',  'manservant',  'fathers',  'divo',  'actor',  'bachelor',  'papa',  'dukes',  'countrymen',  'hosts',  'airmen',  'andropause',  'penis',  'prince',  'governors',  'abbot',  'men',  'widower',  'gentlemen',  'sorcerers',  'sir',  'bridegrooms',  'baron',  'nephew',  'widowers',  'lord',  'brother',  'grooms',  'priest',  'andrology',  'his',  'marquis',  'princes',  'emperors',  'stallion',  'chairman',  'monastery',  'priests',  'boyhood',  'fellas',  'king',  'dudes',  'daddies',  'manservant',  'spokesman',  'tailor',  'cowboys',  'dude',  'bachelors',  'emperor',  'daddy',  'guys',  'enchanter',  'guy',  'fatherhood', \n",
    "                'androgen',  'godfather',  'strongman',  'god',  'patriarch',  'uncle',  'chairmen',  'sir',  'brotherhood',  'host',  'testosterone',  'husband',  'dad',  'steward',  'males',  'spokesmen',  'pa',  'beau',  'stud',  'bachelor',  'wizard',  'sir',  'nephews',  'fathered',  'bull',  'beaus',  'grandson',  'fiances',  'stepfathers',  'grandfathers',  'schoolboy',  'rooster',  'grandsons',  'bachelor',  'cameraman',  'dads',  'him',  'master',  'lad',  'policeman',  'monk',  'actors',  'salesmen',  'boyfriend',  'councilman',  'fella',  'statesman',  'paternal',  'chap',  'landlord',  'lords',  'blokes',  'fraternity',  'duke',  'dancer',  'dudes',  'fiance',\n",
    "                'colts',  'husbands',  'he',  'businessman',  'masseurs',  'hero',  'deer',  'boyfriends',  'kings',  'brothers',  'stepfather',  'son',  'cowboy',  'sons',  'baritone',  'salesman',  'paramour',  'monks',  'headmasters',  'lads',  'congressman',  'househusband',  'priest',  'abbots',  'beard',  'fraternities',  'stewards',  'colt',  'czar',  'stepsons',  'himself',  'boys',  'lions',  'gentleman',  'penis',  'his',  'masseur',  'bulls',  'uncles',  'bloke',  'beards',  'hubby',  'lion',  'sorcerer',  'father',  'gays',  'male',  'waiters',  'sperm',  'prostate',  'stepson',  'businessmen',  'heir',  'waiter',  'headmaster',  'man',  'governor',  'bridegroom', \n",
    "                'grandpa',  'groom',  'dude',  'gay',  'gents',  'boy',  'grandfather',  'gelding',  'roosters',  'priests',  'busboy',  'heros']\n",
    "\n",
    "#added the gendered pairs to the equalizing list (equalizing_lists['gender'] if the pairs are not there already\n",
    "gendered_pairs = list(zip(male_vocab, female_vocab))\n",
    "list_pairs = [tuple for tuple in gendered_pairs if tuple not in equalizing_lists['gender']]\n",
    "equalizing_lists['gender'] = equalizing_lists['gender']+list_pairs\n",
    "\n",
    "#Some of the words were taken from the analogies' templates from Cheng and Manzini.\n",
    "#The list is not the same, however, because some of the words were not neutral, but carried some\n",
    "#relation to the social categories.\n",
    "neutral_words = [\"manager\", \"executive\", \"doctor\", \"lawyer\", \"programmer\",\n",
    "                 \"scientist\", \"soldier\", \"supervisor\", \"rancher\", \"janitor\",\n",
    "                 \"firefighter\", \"officer\", \"secretary\", \"nurse\", \"clerk\", \"artist\",\n",
    "                 \"homemaker\", \"dancer\", \"singer\", \"librarian\", \"maid\", \"hairdresser\", \"stylist\",\n",
    "                 \"receptionist\", \"counselor\", \"leader\", \"farmer\",\n",
    "                 \"engineer\", \"laborer\", \"teacher\",\n",
    "                 \"slave\", \"musician\", \"runner\", \"criminal\", \"homeless\",\n",
    "                 \"greedy\", \"cheap\", \"hairy\", \"liberal\",\n",
    "                 \"judgemental\", \"conservative\", \"familial\",\n",
    "                 \"violent\", \"terrorist\", \"dirty\", \"uneducated\", \"educated\"]\n",
    "\n",
    "\n",
    "#However, also the vocabulary without the gendered words from the list can be conceived as neutral, according to Bolukbasi et al.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the definite sets for debiasing\n",
    "def_set_gender=utils.prepare_def_sets_subspace(def_sets[\"gender\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Evaluation of Slight changes to the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Visualization import *\n",
    "from Scripts.Evaluation import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Setting up parameters and combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset with all parameter combinations: \n",
    "# norm_direction is a parameter that determines whether the bias direction is normalized or not\n",
    "# normalize is a parameter that determines whether the word vectors are normalized before or after debiasing\n",
    "# centralize is a parameter that determines whether the word vectors are centered before using PCA to find the bias subspace\n",
    "import pandas as pd\n",
    "parameters = pd.read_csv('Data/all_parameter_combinations.csv', header=0)\n",
    "parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining variables for the analysis\n",
    "he_embed = dict_vectors['he']\n",
    "she_embed = dict_vectors['she']\n",
    "occupations = ['assistant', 'secretary', 'data scientist', 'scientist', 'politician', 'janitor', 'hairdresser', 'teacher',\n",
    "                'bartender', 'midwife', 'doctor', 'ballerina', 'dancer', 'pediatrician', 'surgeon', 'physician', 'shopkeeper', \n",
    "                  'nurse', 'interior designer', 'architect', 'maid', 'housekeeper', 'soprano', 'baritone', 'servant',  'vocalists',\n",
    "                    'guitarists', 'carpenter', 'clerk', 'manager', 'supervisor', 'driver',\n",
    "               'software developer', 'lawyer', 'pitcher', 'bookkeeper', 'infielder', 'receptionist', 'investigator', 'pundit', \n",
    "               'chancellor', 'maestro', 'lecturer', 'salesperson', 'homemaker', 'receptionist', 'librarian', 'nanny', 'bookkeeper',\n",
    "                 'stylist', 'housekeeper', 'guidance counselor', 'skipper', 'protege', 'philosopher', 'captain', 'architect', 'financier',\n",
    "                 'warrior', 'broadcaster', 'magician', 'figher', 'pilot', 'boss']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that gets all the debiased vectors, vocabularies and word2idx dictionaries for all parameter combinations and stores them in a dictionary\n",
    "def get_debiased_vectors(vectors, dict_vectors, word2idx_cleaned,\n",
    "                         vocab_cleaned,\n",
    "                         equalizing_lists,\n",
    "                         def_set, parameters_df):\n",
    "    grand_dictionary = {}\n",
    "    #loop over indexes of the df\n",
    "    for i in range(len(parameters_df)):\n",
    "        #run the hard_debias function with the parameters of the row and generate a dictionary with the results: key=index, value:dictionary, key=name (vectors, vocab, word2idx), value: the result of the function\n",
    "        debiased_vectors, debiased_vocab, debiased_word2idx, debiased_dict = hard_debias(vectors,\n",
    "                                                                                         dict_vectors,\n",
    "                                                                                         word2idx_cleaned,\n",
    "                                                                                         vocab_cleaned,\n",
    "                                                                                         equalizing_lists,\n",
    "                                                                                         def_set,\n",
    "                                                                                         1,\n",
    "                                                                                         normalize_dir=parameters_df.iloc[\n",
    "                                                                                             i][0],\n",
    "                                                                                         normalize=parameters_df.iloc[i][1],\n",
    "                                                                                         centralizing=parameters_df.iloc[i][2])\n",
    "\n",
    "        #add the variables to the grand dictionary\n",
    "        grand_dictionary[i] = {'vectors': debiased_vectors, 'vocab': debiased_vocab,\n",
    "                               'word2idx': debiased_word2idx, 'dict': debiased_dict}\n",
    "\n",
    "    return grand_dictionary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the grand dictionary\n",
    "grand_dict=get_debiased_vectors(vectors, dict_vec_cleaned, word2idx_cleaned,\n",
    "                     vocab_cleaned,\n",
    "                     equalizing_lists['gender'],\n",
    "                     def_set_gender, parameters)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Bias Pre-Post of selected words.\n",
    "  Using the original and debiased vectors, I calculate bias scores in two ways:\n",
    "  1. Simple Bias Score: cos(v, she_embed)-cos(v, he_embed) for every v in the vocabulary\n",
    "  2. Direct bias score: following Bolukbasi et al. 2016\n",
    "\n",
    "  With this, I get a measure of the debiasing effects per word or the chosen list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the original simple bias as baseline\n",
    "gender_bias_original = compute_gender_simple_bias(\n",
    "    dict_vec_cleaned, he_embed, she_embed)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets a dictionary with the bias scores for all the words in the dataset for all parameter combinations\n",
    "def get_debiased_vectors_scores_plots(grand_dict, dict_vectors, parameters_df, he_embed, she_embed, def_set_gender):\n",
    "    scores_dictionary = {}\n",
    "\n",
    "    #loop over indexes of the df\n",
    "    for i in range(len(parameters_df)):\n",
    "        #debiased_vectors=grand_dict[i]['vectors']\n",
    "        #debiased_vocab=grand_dict[i]['vocab']\n",
    "        #debiased_word2idx=grand_dict[i]['word2idx']\n",
    "        debiased_dict = grand_dict[i]['dict']\n",
    "\n",
    "        # Using the gender bias function to compute the bias of all the words in the limited dataset\n",
    "        #We create a dictionary with the word as key and the bias as value\n",
    "        gender_bias_after_debiasing = compute_gender_simple_bias(\n",
    "            debiased_dict, he_embed, she_embed)\n",
    "\n",
    "        gender_direction = identify_bias_subspace(\n",
    "            dict_vectors, def_set_gender, 1, centralizing=parameters_df.iloc[i][2])\n",
    "        if parameters_df.iloc[i][0]:\n",
    "            gender_direction = utils.normalize(gender_direction)\n",
    "\n",
    "        #use compute_direct_bias to get the scores\n",
    "        direct_gender_bias_original = compute_similarity_to_bias_direction(\n",
    "            dict_vectors, gender_direction)\n",
    "        direct_gender_bias_debiased = compute_similarity_to_bias_direction(\n",
    "            debiased_dict, gender_direction)\n",
    "\n",
    "        scores_dictionary[i] = {'simple_bias': gender_bias_after_debiasing,\n",
    "                                'direct_bias_original': direct_gender_bias_original,\n",
    "                                'direct_bias_debiased': direct_gender_bias_debiased}\n",
    "    return scores_dictionary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the scores dictionary\n",
    "scores_dictionary = get_debiased_vectors_scores_plots(\n",
    "    grand_dict,dict_vectors, parameters, he_embed, she_embed, def_set_gender)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get a bar plot comparing pre-post scores for chosen words\n",
    "def getting_plots_simple_scores(grand_dict, test_words, gender_bias_original, scores_dictionary, parameters_df):\n",
    "    bias_df_all = pd.DataFrame()\n",
    "    for i in range(len(scores_dictionary)):\n",
    "        debiased_vocab = grand_dict[i]['vocab']\n",
    "        gender_bias_debiased = scores_dictionary[i]['simple_bias']\n",
    "        bias_df = get_bias_score_df_from_list(\n",
    "            gender_bias_original, gender_bias_debiased, test_words, vocab_cleaned, debiased_vocab)\n",
    "        #print(\"______________________________________\")\n",
    "        #print('Experiment_'+str(i), ', normalize_direction:', parameters_df.iloc[i][0], ', normalize_vectors:',parameters_df.iloc[i][1], ', centralize:',parameters_df.iloc[i][2])\n",
    "        #plot_bias_bar(bias_df, plot_title=\"Exp_\"+str(i), words_title='words')\n",
    "        bias_df['experiment'] = \"Exp_\"+str(i)+' : ' + str(parameters_df.iloc[i][0])+' / '+str(\n",
    "            parameters_df.iloc[i][1])+' / '+str(parameters_df.iloc[i][2])\n",
    "    #merge all the dataframes\n",
    "        bias_df_all = pd.concat([bias_df_all, bias_df])\n",
    "    return bias_df_all\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df to plot occupation scores\n",
    "bias_df_all_occupations= getting_plots_simple_scores(grand_dict,occupations,gender_bias_original,scores_dictionary, parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get plots of all the bias_df_all faceted by experiment\n",
    "fig = px.bar(bias_df_all_occupations, x='index', y='value', color='variable', barmode='group', facet_col='experiment', facet_col_wrap=2,\n",
    "             labels={'index': 'words', 'value': 'bias score', 'variable': 'bias type'},\n",
    "           title='Bias scores for occupations',\n",
    "           height=1200, width=1000,\n",
    "             template='ggplot2',\n",
    "             color_discrete_sequence=[\"rgb(246,0,0)\", \"rgb(0,118,101)\"])\n",
    "#save the plot\n",
    "fig.write_image(\"Figures/bias_scores_occupations.png\")\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Df to plot neutral words\n",
    "bias_df_all_neutral= getting_plots_simple_scores(grand_dict,neutral_words,gender_bias_original,scores_dictionary, parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get plots of all the bias_df_all faceted by experiment\n",
    "fig = px.bar(bias_df_all_neutral, x='index', y='value', color='variable', barmode='group', facet_col='experiment', facet_col_wrap=2,\n",
    "             labels={'index': 'words', 'value': 'bias score',\n",
    "                     'variable': 'bias type'},\n",
    "             title='Bias scores for occupations',\n",
    "             height=1200, width=1000,\n",
    "             template='ggplot2',\n",
    "             color_discrete_sequence=[\"rgb(246,0,0)\", \"rgb(0,118,101)\"])\n",
    "#save the plot\n",
    "#fig.write_image(\"Figures/bias_scores_neutral.png\")\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get a bar plot comparing pre-post direct bias scores for chosen words\n",
    "def getting_plots_simple_scores(grand_dict, test_words, scores_dictionary, parameters_df):\n",
    "    bias_df_all = pd.DataFrame()\n",
    "    for i in range(len(scores_dictionary)):\n",
    "        debiased_vocab = grand_dict[i]['vocab']\n",
    "        direct_gender_bias_original = scores_dictionary[i]['direct_bias_original']\n",
    "        gender_bias_debiased = scores_dictionary[i]['direct_bias_debiased']\n",
    "        bias_df = get_bias_score_df_from_list(\n",
    "            direct_gender_bias_original, gender_bias_debiased, test_words, vocab_cleaned, debiased_vocab)\n",
    "        #print(\"______________________________________\")\n",
    "        #print('Experiment_'+str(i), ', normalize_direction:', parameters_df.iloc[i][0], ', normalize_vectors:',parameters_df.iloc[i][1], ', centralize:',parameters_df.iloc[i][2])\n",
    "        #plot_bias_bar(bias_df, plot_title=\"Exp_\"+str(i), words_title='words')\n",
    "        bias_df['experiment'] = \"Exp_\"+str(i)+' : ' + str(parameters_df.iloc[i][0])+' / '+str(\n",
    "            parameters_df.iloc[i][1])+' / '+str(parameters_df.iloc[i][2])\n",
    "    #merge all the dataframes\n",
    "        bias_df_all = pd.concat([bias_df_all, bias_df])\n",
    "    return bias_df_all\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots for occupations\n",
    "direct_bias_occupations= getting_plots_simple_scores(grand_dict,neutral_words,scores_dictionary, parameters)\n",
    "direct_bias_occupations.value=direct_bias_occupations.value.astype(float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get plots of all the bias_df_all faceted by experiment\n",
    "fig = px.bar(direct_bias_occupations, x='index', y='value', color='variable', barmode='group', facet_col='experiment', facet_col_wrap=2,\n",
    "             title='Bias scores for occupations',\n",
    "             height=1600, width=1000,\n",
    "             template='ggplot2',\n",
    "             color_discrete_sequence=[\"rgb(246,0,0)\", \"rgb(0,118,101)\"])\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get average bias scores\n",
    "def getting_average_bias_scores(grand_dict, parameters_df, dict_vectors, vocab, def_set_gender):\n",
    "    av_scores = []\n",
    "   \n",
    "    for i in range(len(parameters_df)):\n",
    "        debiased_dict = grand_dict[i]['dict']\n",
    "        debiased_vocab=grand_dict[i]['vocab']\n",
    "        gender_direction=identify_bias_subspace(\n",
    "            dict_vectors, def_set_gender, 1, centralizing = parameters_df.iloc[i][2])\n",
    "        av_bias_original=compute_average_bias(\n",
    "            dict_vectors, vocab, gender_direction)\n",
    "        av_bias_score=compute_average_bias(\n",
    "        debiased_dict, debiased_vocab, gender_direction)\n",
    "        av_scores.append([av_bias_original,av_bias_score])\n",
    "\n",
    "        print('Experiment_'+str(i), ', normalize_direction:',\n",
    "              parameters_df.iloc[i][0], ', normalize_vectors:', parameters_df.iloc[i][1], ', centralize:', parameters_df.iloc[i][2])\n",
    "        print('Average Bias Scores before debiasing', av_scores[i][0])\n",
    "        print('Average Bias Scores after debiasing', av_scores[i][1])\n",
    "    return av_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the average bias scores for the experiments\n",
    "av_scores=getting_average_bias_scores(\n",
    "    grand_dict, parameters, dict_vec_cleaned, vocab_cleaned, def_set_gender)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get df with average scores\n",
    "av_scores_df=pd.DataFrame(av_scores, columns=['original', 'debiased'])\n",
    "#Save it to csv\n",
    "#av_scores_df.to_csv('Data/average_bias_scores.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Visualizing Clusters of feminine and masculine words\n",
    "  Debiasing algorithms are tested through the visualization of the feminine vs masculine clusters. When the clusters are very mingled together, it is said that the debiasing algorithm was successful (as the clusters are no longer linearly separable).\n",
    "\n",
    "  I plotted the clusters for all the experiments and interestingly, there are barely any differences between them. The Precision scores show that the k-means algorithm is having a hard time picking up the two distinct clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting 1000 most biased words: 500 female and 500 male\n",
    "c_w2i, c_vocab, female_words, male_words, y_true=utils.getting_biased_words(gender_bias_original, def_sets['gender'], 500, word2idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to visualizr the clusters\n",
    "%matplotlib inline\n",
    "def visualizing_all_clusters(grand_dict,parameters_df,word_list, y_true, random_state=42):\n",
    "    for i in range(len(parameters_df)):\n",
    "        debiased_vectors=grand_dict[i]['vectors'] \n",
    "        #debiased_vocab=grand_dict[i]['vocab']\n",
    "        debiased_word2idx=grand_dict[i]['word2idx']\n",
    "        #debiased_dict = grand_dict[i]['dict']\n",
    "        gendered_vectors = utils.extract_vectors(\n",
    "            word_list, debiased_vectors, debiased_word2idx)\n",
    "\n",
    "        print('Experiment_'+str(i), ', normalize_direction:',\n",
    "          parameters_df.iloc[i][0], ', normalize_vectors:', parameters_df.iloc[i][1], ', centralize:', parameters_df.iloc[i][2])\n",
    "        cluster_and_visualize(word_list, np.array(gendered_vectors), \n",
    "                                            title=('Glove_Exp'+str(i)+':' + str(parameters_df.iloc[i][0])+\"/\" + str(parameters_df.iloc[i][1])+\"/\"+str(parameters_df.iloc[i][2])), \n",
    "                                            y_true=y_true, \n",
    "                                            random_state=random_state)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the clusters for the 1000 most biased words in the original GloVe\n",
    "gendered_vectors = utils.extract_vectors(\n",
    "    male_words + female_words, vectors_cleaned, word2idx_cleaned)\n",
    "cluster_and_visualize(male_words + female_words,\n",
    "                      np.array(gendered_vectors), 'GloVe_original', y_true, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets visualize the clusters for all the experiments\n",
    "visualizing_all_clusters(grand_dict, parameters,\n",
    "                         male_words + female_words, y_true,42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Random Words Clusters\n",
    "  Although debiasing algorithms transform all the embedding vectors, rarely do they report changes in random words, here I explore the closest words to a random list of words (following Ravfogel). I then plot the original neighbors in the debiased embeddings to evaluate what happened to the original clusters. All the clusters seem disentangled. However, this result must be taken with a grain of salt because tSNE, the plotting algorithm underpinning the plots, modifies the distances between points, although it mostly maintains clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding random words from the vocabulary\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "#set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "#choosing random words from the vocabulary\n",
    "random_words = np.random.choice(vocab_cleaned[:10000], size=20)\n",
    "#Let's take a look at the random words\n",
    "random_words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the neighbors before and after debiasing. It prints the results as a sanity check\n",
    "def get_random_words_clusters(grand_dict, vectors_cleaned,vocab_cleaned, parameters_df, random_words, topn):\n",
    "    model_original = create_KeyedVectors(vectors_cleaned, vocab_cleaned, 300)\n",
    "\n",
    "    for i in range(len(parameters_df)):\n",
    "        debiased_vectors=grand_dict[i]['vectors'] \n",
    "        debiased_vocab=grand_dict[i]['vocab']\n",
    "        model_debiased = create_KeyedVectors(debiased_vectors, debiased_vocab, 300)\n",
    "\n",
    "        words_before_after=finding_neighbors_before_after(random_words, model_original, model_debiased, topn=topn)\n",
    "        print('Experiment_'+str(i), ', normalize_direction:', parameters_df.iloc[i][0], ', normalize_vectors:',parameters_df.iloc[i][1], ', centralize:',parameters_df.iloc[i][2])\n",
    "        print(words_before_after)\n",
    "        \n",
    "get_random_words_clusters(grand_dict, vectors_cleaned,vocab_cleaned, parameters, random_words, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot the position of neighbors to random words before and after debiasing.\n",
    "def plot_random_words_clusters(parameters_df, random_words, topn):\n",
    "    model_original = create_KeyedVectors(vectors_cleaned, vocab_cleaned, 300)\n",
    "    for i in range(len(parameters_df)):\n",
    "        debiased_vectors = grand_dict[i]['vectors']\n",
    "        debiased_vocab = grand_dict[i]['vocab']\n",
    "        model_debiased = create_KeyedVectors(\n",
    "            debiased_vectors, debiased_vocab, 300)\n",
    "        \n",
    "        #This approach was inspired by the following blog post:https://towardsdatascience.com/google-news-and-leo-tolstoy-visualizing-word2vec-word-embeddings-with-t-sne-11558d8bd4d\n",
    "        keys = random_words\n",
    "        embedding_clusters, db_embedding_clusters, word_clusters = get_embeddings_neighbors(\n",
    "            keys, model_original, model_debiased, topn)\n",
    "\n",
    "        n, m, k = embedding_clusters.shape\n",
    "        tsne_model_en_2d = TSNE(perplexity=2, n_components=2,\n",
    "                                init='pca', n_iter=3500, random_state=42)\n",
    "        embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(\n",
    "                                embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "        db_embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(\n",
    "                                db_embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "        print('Experiment_'+str(i), ', normalize_direction:', parameters_df.iloc[i][0], ', normalize_vectors:',parameters_df.iloc[i][1], ', centralize:',parameters_df.iloc[i][2])\n",
    "        \n",
    "        if i==0:\n",
    "            tsne_plot_similar_words('Similar words before Debiasing',\n",
    "                                keys, embeddings_en_2d, word_clusters, 0.7)\n",
    "\n",
    "\n",
    "            tsne_plot_similar_words('Similar words after Debiasing',\n",
    "                        keys, db_embeddings_en_2d, word_clusters, 0.7)\n",
    "        else:\n",
    "            tsne_plot_similar_words('Similar words after Debiasing',\n",
    "                                    keys, db_embeddings_en_2d, word_clusters, 0.7)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_words_clusters(parameters, random_words, 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Saving Embeddings on a txt file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the debiased vectors for future use\n",
    "for i in range(len(parameters)):\n",
    "  glove.save_in_word2vec_format(\n",
    "      grand_dict[i]['vectors'], grand_dict[i]['vocab'], \"./Data/DebiasedVectors/vecs.300\"+'exp'+str(i)+\".txt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MT_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
