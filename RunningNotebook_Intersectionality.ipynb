{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.ProcessingEmbeddings import *\n",
    "import Scripts.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data/word2vec-google-news-300.txt embeddings\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Creating an embeddings object: 400k words, 50 dimensions\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#glove=Embeddings('Data/glove-wiki-gigaword-300.txt', gensim=False)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m word2vec\u001b[39m=\u001b[39mEmbeddings(\u001b[39m'\u001b[39;49m\u001b[39mData/word2vec-google-news-300.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, gensim\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Python/VersionControl/MT_DebiasingAlgorithms/Scripts/ProcessingEmbeddings.py:36\u001b[0m, in \u001b[0;36mEmbeddings.__init__\u001b[0;34m(self, file, gensim)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile \u001b[39m=\u001b[39m file\n\u001b[1;32m     35\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoading\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile, \u001b[39m\"\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m KeyedVectors\u001b[39m.\u001b[39;49mload_word2vec_format(file, binary\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectors, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwords, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword2idx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_words_vectors(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MT_env/lib/python3.10/site-packages/gensim/models/keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1672\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_word2vec_format\u001b[39m(\n\u001b[1;32m   1674\u001b[0m         \u001b[39mcls\u001b[39m, fname, fvocab\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m, unicode_errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1675\u001b[0m         limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, datatype\u001b[39m=\u001b[39mREAL, no_header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1676\u001b[0m     ):\n\u001b[1;32m   1677\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m \n\u001b[1;32m   1679\u001b[0m \u001b[39m    Warnings\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \n\u001b[1;32m   1718\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1719\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[1;32m   1720\u001b[0m         \u001b[39mcls\u001b[39;49m, fname, fvocab\u001b[39m=\u001b[39;49mfvocab, binary\u001b[39m=\u001b[39;49mbinary, encoding\u001b[39m=\u001b[39;49mencoding, unicode_errors\u001b[39m=\u001b[39;49municode_errors,\n\u001b[1;32m   1721\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit, datatype\u001b[39m=\u001b[39;49mdatatype, no_header\u001b[39m=\u001b[39;49mno_header,\n\u001b[1;32m   1722\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MT_env/lib/python3.10/site-packages/gensim/models/keyedvectors.py:2069\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   2065\u001b[0m         _word2vec_read_binary(\n\u001b[1;32m   2066\u001b[0m             fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[1;32m   2067\u001b[0m         )\n\u001b[1;32m   2068\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2069\u001b[0m         _word2vec_read_text(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\n\u001b[1;32m   2070\u001b[0m \u001b[39mif\u001b[39;00m kv\u001b[39m.\u001b[39mvectors\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(kv):\n\u001b[1;32m   2071\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m   2072\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mduplicate words detected, shrinking matrix size from \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2073\u001b[0m         kv\u001b[39m.\u001b[39mvectors\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39mlen\u001b[39m(kv),\n\u001b[1;32m   2074\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MT_env/lib/python3.10/site-packages/gensim/models/keyedvectors.py:1974\u001b[0m, in \u001b[0;36m_word2vec_read_text\u001b[0;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[39mif\u001b[39;00m line \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1973\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munexpected end of input; is count incorrect or file otherwise damaged?\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1974\u001b[0m word, weights \u001b[39m=\u001b[39m _word2vec_line_to_vector(line, datatype, unicode_errors, encoding)\n\u001b[1;32m   1975\u001b[0m _add_word_to_kv(kv, counts, word, weights, vocab_size)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MT_env/lib/python3.10/site-packages/gensim/models/keyedvectors.py:1980\u001b[0m, in \u001b[0;36m_word2vec_line_to_vector\u001b[0;34m(line, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_word2vec_line_to_vector\u001b[39m(line, datatype, unicode_errors, encoding):\n\u001b[1;32m   1979\u001b[0m     parts \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mto_unicode(line\u001b[39m.\u001b[39mrstrip(), encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39municode_errors)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1980\u001b[0m     word, weights \u001b[39m=\u001b[39m parts[\u001b[39m0\u001b[39m], [datatype(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m parts[\u001b[39m1\u001b[39m:]]\n\u001b[1;32m   1981\u001b[0m     \u001b[39mreturn\u001b[39;00m word, weights\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MT_env/lib/python3.10/site-packages/gensim/models/keyedvectors.py:1980\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_word2vec_line_to_vector\u001b[39m(line, datatype, unicode_errors, encoding):\n\u001b[1;32m   1979\u001b[0m     parts \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mto_unicode(line\u001b[39m.\u001b[39mrstrip(), encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39municode_errors)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1980\u001b[0m     word, weights \u001b[39m=\u001b[39m parts[\u001b[39m0\u001b[39m], [datatype(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m parts[\u001b[39m1\u001b[39m:]]\n\u001b[1;32m   1981\u001b[0m     \u001b[39mreturn\u001b[39;00m word, weights\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Creating an embeddings object: 400k words, 50 dimensions\n",
    "#glove=Embeddings('Data/glove-wiki-gigaword-300.txt', gensim=False)\n",
    "word2vec=Embeddings('Data/word2vec-google-news-300.txt', gensim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the attributes of the embeddings \n",
    "vectors=word2vec.vectors\n",
    "word2idx=word2vec.word2idx\n",
    "vocab=word2vec.words\n",
    "dict_vectors = word2vec.get_word_vector_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying the attributes: there shouldn't be any null values\n",
    "np.isnan(vectors).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing puntuation and numbers from the embeddings\n",
    "vocab_cleaned, vectors_cleaned, word2idx_cleaned, dict_vec_cleaned = word2vec.limit_vocab(\n",
    "    vectors, word2idx, vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if vector are normalized\n",
    "np.apply_along_axis(np.linalg.norm, 1, vectors_cleaned)\n",
    "#They are not!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard-Debias Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.HardDebias import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender specific vocabulary from Bolukbasi's paper.\n",
    "gender_specific = []\n",
    "female_vocab = []\n",
    "male_vocab = []\n",
    "with open('./Data/male_word_file.txt') as f:\n",
    "    male_vocab = [line.strip() for line in f]\n",
    "\n",
    "with open('./Data/female_word_file.txt') as f:\n",
    "    for l in f:\n",
    "        female_vocab.append(l.strip())\n",
    "\n",
    "gender_specific = female_vocab+female_vocab\n",
    "\n",
    "with codecs.open('./Data/gender_specific_full.json') as f:\n",
    "    gender_specific.extend(json.load(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the definitional sets to calculate afterwards the gender direction. The first 10 gender sets were proposed by Bolukbasi et al. (2016)\n",
    "#Definitional sets for race where proposed by Manzini et al. in Multiclass debiasing of embeddings: https://github.com/TManzini/DebiasMulticlassWordEmbedding/blob/master/Debiasing/data/vocab/race_attributes_optm.json\n",
    "\n",
    "def_sets={\n",
    "    \"gender\" : [\n",
    "    ['she', 'he'], ['herself', 'himself'], ['her', 'his'], ['daughter', 'son'], ['girl', 'boy'],\n",
    "    ['mother', 'father'], ['woman', 'man'], ['mary', 'john'], ['gal', 'guy'], ['female', 'male'],['aunt', 'uncle']],\n",
    "    \n",
    "    \"race\":[\n",
    "\t\t[\"black\", \"caucasian\", \"asian\", \"hispanic\"],\n",
    "\t\t[\"african\", \"caucasian\", \"asian\", \"hispanic\"],\n",
    "\t\t[\"black\", \"white\", \"asian\", \"latino\"],\n",
    "\t\t[\"africa\", \"europe\", \"asia\", \"mexico\"],\n",
    "\t\t[\"africa\", \"america\", \"china\", \"latin-america\"],\n",
    "    ]\n",
    "\t}\n",
    "\n",
    "#Equalizing pairs for gender debiasing were first published by Bolukbasi et al. in https://github.com/tolga-b/debiaswe/blob/master/data/equalize_pairs.json\n",
    "# Equalizing sets for race where defined by Manzini as equal to the defining set (Manzini et al., 2019.p.3)\n",
    "equalizing_lists = {\n",
    "    \"gender\": [\n",
    "        [\"monastery\", \"convent\"], [\"spokesman\", \"spokeswoman\"], [\n",
    "            \"Catholic_priest\", \"nun\"], [\"Dad\", \"Mom\"], [\"Men\", \"Women\"],\n",
    "        [\"councilman\", \"councilwoman\"], [\"grandpa\", \"grandma\"], [\n",
    "            \"grandsons\", \"granddaughters\"], [\"prostate_cancer\", \"ovarian_cancer\"],\n",
    "        [\"testosterone\", \"estrogen\"], [\"uncle\", \"aunt\"], [\n",
    "            \"wives\", \"husbands\"], [\"Father\", \"Mother\"], [\"Grandpa\", \"Grandma\"],\n",
    "        [\"He\", \"She\"], [\"boy\", \"girl\"], [\"boys\", \"girls\"], [\"brother\", \"sister\"], [\n",
    "            \"brothers\", \"sisters\"], [\"businessman\", \"businesswoman\"],\n",
    "        [\"chairman\", \"chairwoman\"], [\"colt\", \"filly\"], [\"congressman\",\n",
    "                                                        \"congresswoman\"], [\"dad\", \"mom\"], [\"dads\", \"moms\"], [\"dudes\", \"gals\"],\n",
    "        [\"ex_girlfriend\", \"ex_boyfriend\"], [\"father\", \"mother\"], [\n",
    "            \"fatherhood\", \"motherhood\"], [\"fathers\", \"mothers\"], [\"fella\", \"granny\"],\n",
    "        [\"fraternity\", \"sorority\"], [\"gelding\", \"mare\"], [\"gentleman\", \"lady\"], [\n",
    "            \"gentlemen\", \"ladies\"], [\"grandfather\", \"grandmother\"],\n",
    "        [\"grandson\", \"granddaughter\"], [\"he\", \"she\"], [\"himself\", \"herself\"], [\n",
    "            \"his\", \"her\"], [\"king\", \"queen\"], [\"kings\", \"queens\"],\n",
    "        [\"male\", \"female\"], [\"males\", \"females\"], [\"man\", \"woman\"], [\n",
    "            \"men\", \"women\"], [\"nephew\", \"niece\"], [\"prince\", \"princess\"],\n",
    "        [\"schoolboy\", \"schoolgirl\"], [\"son\", \"daughter\"], [\"sons\", \"daughters\"], [\"twin_brother\", \"twin_sister\"]],\n",
    "\n",
    "    \"race\": [\n",
    "        [\"black\", \"caucasian\", \"asian\"],\n",
    "      \t[\"african\", \"caucasian\", \"asian\"],\n",
    "      \t[\"black\", \"white\", \"asian\"],\n",
    "      \t[\"africa\", \"america\", \"asia\"],\n",
    "      \t[\"africa\", \"america\", \"china\"],\n",
    "      \t[\"africa\", \"europe\", \"asia\"]\n",
    "    ]}\n",
    "\n",
    "#Some of the words were taken from the analogies' templates from Cheng and Manzini.\n",
    "#The list is not the same, however, because some of the words were not neutral, but carried some\n",
    "#relation to the social categories.\n",
    "neutral_words = [\"manager\", \"executive\", \"doctor\", \"lawyer\", \"programmer\",\n",
    "                 \"scientist\", \"soldier\", \"supervisor\", \"rancher\", \"janitor\",\n",
    "                 \"firefighter\", \"officer\", \"secretary\", \"nurse\", \"clerk\", \"artist\",\n",
    "                 \"homemaker\", \"dancer\", \"singer\", \"librarian\", \"maid\", \"hairdresser\", \"stylist\",\n",
    "                 \"receptionist\", \"counselor\", \"leader\", \"farmer\",\n",
    "                 \"engineer\", \"laborer\", \"teacher\",\n",
    "                 \"slave\", \"musician\", \"runner\", \"criminal\", \"homeless\",\n",
    "                 \"greedy\", \"cheap\", \"hairy\", \"liberal\",\n",
    "                 \"judgemental\", \"conservative\", \"familial\",\n",
    "                 \"violent\", \"terrorist\", \"dirty\", \"uneducated\", \"educated\"]\n",
    "\n",
    "\n",
    "#However, also the vocabulary without the gendered words from the list can be conceived as neutral, according to Bolukbasi et al.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lists of names for validation\n",
    "#Adapted from Speer's tutorial on racism in sentiment analysis. http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/\n",
    "names_ethnicity = {\n",
    "    # The first two lists are from the Caliskan et al. appendix describing the\n",
    "    # Word Embedding Association Test.\n",
    "    'White': [\n",
    "        'Adam', 'Chip', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Ian', 'Justin',\n",
    "        'Ryan', 'Andrew', 'Fred', 'Jack', 'Matthew', 'Stephen', 'Brad', 'Greg', 'Jed',\n",
    "        'Paul', 'Todd', 'Brandon', 'Hank', 'Jonathan', 'Peter', 'Wilbur', 'Amanda',\n",
    "        'Courtney', 'Heather', 'Melanie', 'Sara', 'Amber', 'Crystal', 'Katie',\n",
    "        'Meredith', 'Shannon', 'Betsy', 'Donna', 'Kristin', 'Nancy', 'Stephanie',\n",
    "        'Bobbie-Sue', 'Ellen', 'Lauren', 'Peggy', 'Sue-Ellen', 'Colleen', 'Emily',\n",
    "        'Megan', 'Rachel', 'Wendy'\n",
    "    ],\n",
    "\n",
    "    'Black': [\n",
    "        'Alonzo', 'Jamel', 'Lerone', 'Percell', 'Theo', 'Alphonse', 'Jerome',\n",
    "        'Leroy', 'Rasaan', 'Torrance', 'Darnell', 'Lamar', 'Lionel', 'Rashaun',\n",
    "        'Tyree', 'Deion', 'Lamont', 'Malik', 'Terrence', 'Tyrone', 'Everol',\n",
    "        'Lavon', 'Marcellus', 'Terryl', 'Wardell', 'Aiesha', 'Lashelle', 'Nichelle',\n",
    "        'Shereen', 'Temeka', 'Ebony', 'Latisha', 'Shaniqua', 'Tameisha', 'Teretha',\n",
    "        'Jasmine', 'Latonya', 'Shanise', 'Tanisha', 'Tia', 'Lakisha', 'Latoya',\n",
    "        'Sharise', 'Tashika', 'Yolanda', 'Lashandra', 'Malika', 'Shavonn',\n",
    "        'Tawanda', 'Yvette'\n",
    "    ],\n",
    "    \n",
    "    # This list comes from statistics about common Hispanic-origin names in the US.\n",
    "    'Hispanic': [\n",
    "        'Juan', 'José', 'Miguel', 'Luís', 'Jorge', 'Santiago', 'Matías', 'Sebastián',\n",
    "        'Mateo', 'Nicolás', 'Alejandro', 'Samuel', 'Diego', 'Daniel', 'Tomás',\n",
    "        'Juana', 'Ana', 'Luisa', 'María', 'Elena', 'Sofía', 'Isabella', 'Valentina',\n",
    "        'Camila', 'Valeria', 'Ximena', 'Luciana', 'Mariana', 'Victoria', 'Martina'\n",
    "    ],\n",
    "    \n",
    "   \n",
    "}\n",
    "#Following Bolukbasi et al. Implementing notebook: https://github.com/tolga-b/debiaswe/blob/master/tutorial_example1.ipynb\n",
    "names = [\"Emily\", \"Aisha\", \"Anne\", \"Keisha\", \"Jill\", \"Tamika\", \"Allison\", \"Lakisha\", \"Laurie\", \"Tanisha\", \"Sarah\",\n",
    "         \"Latoya\", \"Meredith\", \"Kenya\", \"Carrie\", \"Latonya\", \"Kristen\", \"Ebony\", \"Todd\", \"Rasheed\", \"Neil\", \"Tremayne\",\n",
    "         \"Geoffrey\", \"Kareem\", \"Brett\", \"Darnell\", \"Brendan\", \"Tyrone\", \"Greg\", \"Hakim\", \"Matthew\", \"Jamal\", \"Jay\",\n",
    "         \"Leroy\", \"Brad\", \"Jermaine\"]\n",
    "#names_group1 = [names[2 * i] for i in range(len(names) // 2)]\n",
    "#names_group2 = [names[2 * i + 1] for i in range(len(names) // 2)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the definite sets for debiasing\n",
    "def_set_gender=utils.prepare_def_sets_subspace(def_sets[\"gender\"])\n",
    "def_set_race=utils.prepare_def_sets_subspace(def_sets[\"race\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the better way to find the Bias direction\n",
    "The success of hard debiasing algorithms lies on their capacity to find the appropriate bias direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the words in the female_vocab that are also in the embeddings\n",
    "female_words_emb=[word for word in female_vocab if word in dict_vec_cleaned.keys()]\n",
    "male_words_emb = [word for word in male_vocab if word in dict_vec_cleaned.keys()]\n",
    "\n",
    "print('Number of female words in embeddings:', len(female_words_emb))\n",
    "print('Number of male words in embeddings:', len(male_words_emb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the gender directions\n",
    "gen_dir_centralized=identify_bias_subspace(dict_vec_cleaned, def_set_gender, 1, centralizing=True)\n",
    "gen_dir=identify_bias_subspace(dict_vec_cleaned, def_set_gender, 1, centralizing=False)\n",
    "\n",
    "#flattening them\n",
    "gen_dir_centralized_flat=np.squeeze(gen_dir_centralized)\n",
    "gen_dir_flat=np.squeeze(gen_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the similarity of a word through cosine similarity to the bias direction\n",
    "def compute_similarity_to_bias_direction(dict_vec_cleaned, bias_direction):\n",
    "    bias_direction = bias_direction / np.linalg.norm(bias_direction)\n",
    "    similarity = {}\n",
    "    for word in dict_vec_cleaned.keys():\n",
    "        dict_vec_cleaned[word]=dict_vec_cleaned[word]/np.linalg.norm(dict_vec_cleaned[word])\n",
    "        similarity[word]=utils.cosine_similarity(bias_direction, dict_vec_cleaned[word])\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Evaluation import compute_gender_simple_bias, compute_similarity_to_bias_direction\n",
    "similarity=compute_similarity_to_bias_direction(dict_vec_cleaned, gen_dir_flat)\n",
    "similarity_centralized=compute_similarity_to_bias_direction(dict_vec_cleaned, gen_dir_centralized_flat)\n",
    "simple_gender_bias=compute_gender_simple_bias(dict_vec_cleaned, dict_vec_cleaned['he'], dict_vec_cleaned['she'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "#function to get the most biased words in dict_vec_cleaned rated my similarity to the bias direction\n",
    "def get_most_biased_words_similarity(similarity, n_words=2500):\n",
    "    #get the absolute values of the similarity values\n",
    "    similarity = {word: abs(sim) for word, sim in similarity.items()}\n",
    "    #sort the similarity values\n",
    "    sorted_similarity =sorted(similarity.items(), key=itemgetter(1), reverse=True)\n",
    "    biased_words = [word for word, bias in sorted_similarity[:n_words*2]]\n",
    "    neutral_words = [word for word, bias in sorted_similarity[-n_words:]]\n",
    "    return biased_words, neutral_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_words, neutral_words=get_most_biased_words_similarity(similarity, n_words=40000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count how many female_words_emb and male_words_emb are in the biased_words\n",
    "def count_gendered_words_in_most_biased(female_words, male_words, biased_words):\n",
    "    count_female=0\n",
    "    count_male=0\n",
    "    data={}\n",
    "    for word in set(female_words):\n",
    "        if word in set(biased_words):\n",
    "            count_female+=1\n",
    "\n",
    "    for word in set(male_words):\n",
    "        if word in set(biased_words):\n",
    "            count_male+=1\n",
    "    \n",
    "    data.update({'count_female': count_female, 'proportion_female': count_female/len(female_words),\n",
    "                     'count_male': count_male, 'proportion_male': count_male/len(male_words)})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_gendered_words_in_most_biased(female_words_emb, male_words_emb, biased_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_words_centralized, neutral_words_centralized=get_most_biased_words_similarity(similarity_centralized, n_words=40000)\n",
    "count_gendered_words_in_most_biased(female_words_emb, male_words_emb, biased_words_centralized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, female_simple, male_simple, _ = utils.getting_biased_words(\n",
    "    simple_gender_bias, def_sets['gender'], 40000, word2idx)\n",
    "\n",
    "count_gendered_words_in_most_biased(female_words_emb, male_words_emb,female_simple+male_simple )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#get a dataframe with the bias scores of the female_words_emb and male_words_emb in the similarity, similarity_centralized and simple_gender_bias\n",
    "def get_df_bias_scores(word_list, similarity, similarity_centralized,simple_bias_score):\n",
    "    scores={}\n",
    "    for word in word_list:\n",
    "        scores[word] = {\"similarity_score\": -(similarity[word]),\n",
    "                        \"centralized_similarity_score\": (similarity_centralized[word]),\n",
    "                        \"simple_bias_score\": simple_bias_score[word]}\n",
    "    df=pd.DataFrame.from_dict(scores, orient='index')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_female=get_df_bias_scores(female_words_emb, similarity, similarity_centralized,simple_gender_bias)\n",
    "df_male=get_df_bias_scores(male_words_emb, similarity, similarity_centralized,simple_gender_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the dataframe according to the simple_gender_bias column\n",
    "most_female_bias=df_female.sort_values(by=['simple_bias_score'], ascending=False, inplace=True)\n",
    "most_male_bias=df_male.sort_values(by=['simple_bias_score'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a bar plot of the top 20 most biased words with all the scores of the three methods\n",
    "import plotly_express as px\n",
    "\n",
    "def plot_top_biased_words(df, n_words=20):\n",
    "    df_top=df.head(n_words)\n",
    "    #remove the simple_bias_score column\n",
    "    df_top=df_top.drop(columns=['simple_bias_score'])\n",
    "    df_top=df_top.reset_index()\n",
    "    df_top=df_top.rename(columns={'index': 'word'})\n",
    "    df_top=df_top.melt(id_vars=['word'], var_name='score_type', value_name='score')\n",
    "    fig = px.bar(df_top, x=\"word\", y=\"score\", color=\"score_type\", barmode=\"group\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "plot_top_biased_words(df_female, n_words=20)\n",
    "plot_top_biased_words(df_male, n_words=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the similarity scores into a dataframe to find the 20 words with the highest similarity score\n",
    "df_similarity=pd.DataFrame.from_dict(similarity, orient='index')\n",
    "df_similarity=df_similarity.rename(columns={0: 'similarity_score'})\n",
    "df_similarity.sort_values(by=['similarity_score'], ascending=False, inplace=True)\n",
    "df_similarity_male=df_similarity.head(20)\n",
    "df_similarity_female=df_similarity.tail(20)\n",
    "\n",
    "print('Top biased words according to the similarity score:',biased_words[:20])\n",
    "\n",
    "#turn the centralized similarity scores into a dataframe to find the 20 words with the highest similarity score\n",
    "df_similarity_centralized=pd.DataFrame.from_dict(similarity_centralized, orient='index')\n",
    "df_similarity_centralized=df_similarity_centralized.rename(columns={0: 'similarity_score'})\n",
    "df_similarity_centralized.sort_values(by=['similarity_score'], ascending=False, inplace=True)\n",
    "df_centralized_female= df_similarity_centralized.head(20)\n",
    "df_centralized_male=df_similarity_centralized.tail(20)\n",
    "\n",
    "print('Top biased words according to the centralized similarity score:',biased_words_centralized[:20])\n",
    "\n",
    "#simple_biased = {word: abs(sim) for word, sim in simple_gender_bias.items()}\n",
    "df_simple_bias = pd.DataFrame.from_dict(simple_gender_bias, orient='index')\n",
    "df_simple_bias=df_simple_bias.rename(columns={0: 'simple_bias_score'})\n",
    "df_simple_bias.sort_values(by=['simple_bias_score'], ascending=False, inplace=True)\n",
    "df_simple_fem=df_simple_bias.head(20)\n",
    "df_simple_masc=df_simple_bias.tail(20)\n",
    "print('Top biased words simple_score', list(df_simple_bias.head(10).index)+list(df_simple_bias.tail(10).index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centralized_male\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a histogram of the similarity.values()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def plot_histogram(similarity, title):\n",
    "    plt.hist(similarity.values())\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(similarity, 'Histogram of similarity values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(similarity_centralized, 'Histogram of centralized similarity values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(simple_gender_bias, 'Histogram of simple gender bias values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the words in similirity that have values 0\n",
    "def get_words_with_value_zero(similarity):\n",
    "    words=[]\n",
    "    for word in similarity.keys():\n",
    "        if np.allclose(similarity[word],0.5):\n",
    "            words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_words_with_value_zero(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
