{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProcessingEmbeddings import *\n",
    "from HardDebias import *\n",
    "from INLP import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC, SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove-wiki-gigaword-50 embeddings\n",
      "vectors shape: (400000, 50), word2idx length: 400000, vocab length: 400000\n"
     ]
    }
   ],
   "source": [
    "glove=Embeddings('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=glove.vectors\n",
    "word2idx=glove.word2idx\n",
    "vocab=glove.words\n",
    "dict_vectors = glove.get_word_vector_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(vectors).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender specific vocabulary:\n",
    "gender_specific=[]\n",
    "with open('./Data/male_word_file.txt') as f:\n",
    "    gender_specific = [line.strip() for line in f]\n",
    "\n",
    "with open('./Data/female_word_file.txt') as f:\n",
    "    for l in f:\n",
    "        gender_specific.append(l.strip())\n",
    "\n",
    "with codecs.open('./Data/gender_specific_full.json') as f:\n",
    "    gender_specific.extend(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:00<00:00, 626097.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of limited vocabulary: 326614\n"
     ]
    }
   ],
   "source": [
    "# Getting a limited vocabulary to debias the embeddings.\n",
    "vocab_cleaned, vectors_cleaned, word2idx_cleaned, dict_vec_cleaned = glove.limit_vocab(vectors, word2idx, vocab, exclude=gender_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the definitional sets to calculate afterwards the gender direction. The first 10 gender sets were proposed by Bolukbasi et al. (2016)\n",
    "#Definitional sets for race where proposed by Manzini et al. in Multiclass debiasing of embeddings: https://github.com/TManzini/DebiasMulticlassWordEmbedding/blob/master/Debiasing/data/vocab/race_attributes_optm.json\n",
    "\n",
    "def_sets={\n",
    "    \"gender\" : [\n",
    "    ['she', 'he'], ['herself', 'himself'], ['her', 'his'], ['daughter', 'son'], ['girl', 'boy'],\n",
    "    ['mother', 'father'], ['woman', 'man'], ['mary', 'john'], ['gal', 'guy'], ['female', 'male'],['aunt', 'uncle']],\n",
    "    \n",
    "    \"race\":[\n",
    "\t\t[\"black\", \"caucasian\", \"asian\"],\n",
    "\t\t[\"african\", \"caucasian\", \"asian\"],\n",
    "\t\t[\"black\", \"white\", \"asian\"],\n",
    "\t\t[\"africa\", \"america\", \"asia\"],\n",
    "\t\t[\"africa\", \"america\", \"china\"],\n",
    "\t\t[\"africa\", \"europe\", \"asia\"]\n",
    "    ], \n",
    "    \"religion\":[\n",
    "\t\t[\"judaism\", \"christianity\", \"islam\"],\n",
    "\t\t[\"jew\", \"christian\", \"muslim\"],\n",
    "    [\"synagogue\", \"church\", \"mosque\"],\n",
    "    [\"torah\", \"bible\", \"quran\"],\n",
    "    [\"rabbi\", \"priest\", \"imam\"]\n",
    "\t]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equalizing pairs for gender debiasing were first published by Bolukbasi et al. in https://github.com/tolga-b/debiaswe/blob/master/data/equalize_pairs.json\n",
    "# Equalizing sets for race and religion where defined by Manzini as equal to the defining set (Manzini et al., 2019.p.3)\n",
    "equalizing_lists = {\n",
    "    \"gender\": [\n",
    "        [\"monastery\", \"convent\"], [\"spokesman\", \"spokeswoman\"], [\"Catholic_priest\", \"nun\"], [\"Dad\", \"Mom\"], [\"Men\", \"Women\"],\n",
    "        [\"councilman\", \"councilwoman\"], [\"grandpa\", \"grandma\"], [\"grandsons\", \"granddaughters\"], [\"prostate_cancer\", \"ovarian_cancer\"],\n",
    "        [\"testosterone\", \"estrogen\"], [\"uncle\", \"aunt\"], [\"wives\", \"husbands\"], [\"Father\", \"Mother\"], [\"Grandpa\", \"Grandma\"],\n",
    "        [\"He\", \"She\"], [\"boy\", \"girl\"], [\"boys\", \"girls\"], [\"brother\", \"sister\"], [\"brothers\", \"sisters\"], [\"businessman\", \"businesswoman\"],\n",
    "        [\"chairman\", \"chairwoman\"], [\"colt\", \"filly\"], [\"congressman\", \"congresswoman\"], [\"dad\", \"mom\"], [\"dads\", \"moms\"], [\"dudes\", \"gals\"],\n",
    "        [\"ex_girlfriend\", \"ex_boyfriend\"], [\"father\", \"mother\"], [\"fatherhood\", \"motherhood\"], [\"fathers\", \"mothers\"], [\"fella\", \"granny\"],\n",
    "        [\"fraternity\", \"sorority\"], [\"gelding\", \"mare\"], [\"gentleman\", \"lady\"], [\"gentlemen\", \"ladies\"], [\"grandfather\", \"grandmother\"],\n",
    "        [\"grandson\", \"granddaughter\"], [\"he\", \"she\"], [\"himself\", \"herself\"], [\"his\", \"her\"], [\"king\", \"queen\"], [\"kings\", \"queens\"],\n",
    "        [\"male\", \"female\"], [\"males\", \"females\"], [\"man\", \"woman\"], [\"men\", \"women\"], [\"nephew\", \"niece\"], [\"prince\", \"princess\"], \n",
    "        [\"schoolboy\", \"schoolgirl\"], [\"son\", \"daughter\"], [\"sons\", \"daughters\"], [\"twin_brother\", \"twin_sister\"]],\n",
    "\n",
    "    \"race\": [\n",
    "        [\"black\", \"caucasian\", \"asian\"],\n",
    "      \t[\"african\", \"caucasian\", \"asian\"],\n",
    "      \t[\"black\", \"white\", \"asian\"],\n",
    "      \t[\"africa\", \"america\", \"asia\"],\n",
    "      \t[\"africa\", \"america\", \"china\"],\n",
    "      \t[\"africa\", \"europe\", \"asia\"]\n",
    "    ],\n",
    "    \"religion\": [\n",
    "        [\"judaism\", \"christianity\", \"islam\"],\n",
    "        [\"jew\", \"christian\", \"muslim\"],\n",
    "        [\"synagogue\", \"church\", \"mosque\"],\n",
    "        [\"torah\", \"bible\", \"quran\"],\n",
    "        [\"rabbi\", \"priest\", \"imam\"]\n",
    "    ]}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words considered: 2\n",
      "Running PCA with 1 components\n",
      "TOP MASC: ('vulva', 'ilirska', 'sopra', 'seacole', 'konstantinovna', 'phagan', 'ivanovna', 'chromatids', 'sistership', 'lactating', 'aldermanbury', 'chromatid', 'antipolis', 'masumeh', 'ruwart', 'benedicta', 'agia', 'dasi', 'triada', 'maharani', 'gothel', 'woolnoth', 'miscarries', 'popova', 'mizzenmast', 'catharina', 'czestochowa', 'nikolayevna', 'lehzen', 'desnuda', 'herøy', 'murten', 'caesonia', 'mulleavy', 'aghia', 'ludwika', 'ignacia', 'parvomay', 'ferroviario', 'gaitskill', 'tanztheater', 'skłodowska-curie', 'vissi', 'jumonji', 'philomela', 'mahatmya', 'grebenkina', 'rafaela', 'viletta', 'romanova')\n",
      "-------------------------\n",
      "TOP FEM: ('inienger', 'boonyaratkalin', 'abdulsalami', 'jets', 'sonthi', 'scuds', 'voreqe', 'technicals', 'strategists', 'fired', 'valiquette', 'ac-130', 'tactic', 'patriot', 'defensive', 'singirok', 'kassam', 'greifeld', 'offensive', 'boonyaratglin', 'staubach', 'tactics', 'dannatt', 'sacking', 'kfir', 'firing', 'linemen', 'abdulsalam', 'lillee', 'midlevel', 'strike', 'volcanologists', 'gen.', 'commentators', 'chiefs', 'postolos', 'interception', 'preemptive', 'receivers', 'emptive', 'pundits', 'counterattacks', 'gunships', 'feehery', 'pac-3', 'defense', 'incoming', 'quarterbacks', 'halutz', '35-billion')\n",
      "-------------------------\n",
      "Random Neutral: ('fabergé', 'hissatsu', 'centerback', 'abey', 'hise', 'manuvakola', 'homewood', 'moustafa', 'yeomen', 'kanat', '69.63', 'reinvested', 'russophile', 'strategoi', 'tagi', 'undissolved', 'pre-installed', 'argentum', 'melquiades', 'ketterer', 'fechner', 'matveyev', 'orrefors', 'poer', 'bogard', 'castroviejo', '45-29', 'gabbed', '15-april', 'livolsi', 'summiteers', 'koodo', 'vardhana', 'betacam', '500-page', 'noodle', 'casaroli', 'kangs', 'domenick', 'generalities', 'volkan', '103.28', 'popover', 'ratomir', 'freema', 'ostap', 'bilingue', 'tisma', '79.91', 'gorgon')\n"
     ]
    }
   ],
   "source": [
    "num_vectors_per_class = 7500\n",
    "\n",
    "#gender_direction=algorithm1.find_gender_direction(vectors, word2idx_cleaned)\n",
    "\n",
    "#gender_vecs = [glove.model[p[0]] - glove.model[p[1]] for p in gendered_pairs]\n",
    "#pca = PCA(n_components=1)\n",
    "#pca.fit(gender_vecs)\n",
    "gender_direction = identify_bias_subspace(dict_vec_cleaned, def_set_gender, 1, centralizing=True)\n",
    "gender_direction = np.squeeze(gender_direction)\n",
    "\n",
    "gender_unit_vec = gender_direction/np.linalg.norm(gender_direction)\n",
    "masc_words_and_scores, fem_words_and_scores, neut_words_and_scores = getting_classes_for_INLP(gender_vector=gender_direction, model=glove.model, n = 7500)\n",
    "\n",
    "masc_words, masc_scores = list(zip(*masc_words_and_scores))\n",
    "neut_words, neut_scores = list(zip(*neut_words_and_scores))\n",
    "fem_words, fem_scores = list(zip(*fem_words_and_scores))\n",
    "masc_vecs, fem_vecs = glove.get_vectors_from_list(masc_words), glove.get_vectors_from_list(fem_words)\n",
    "neut_vecs = glove.get_vectors_from_list(neut_words)\n",
    "\n",
    "n = min(3000, num_vectors_per_class)\n",
    "all_significantly_biased_words = masc_words[:n] + fem_words[:n]\n",
    "all_significantly_biased_vecs =  np.concatenate((masc_vecs[:n], fem_vecs[:n]))\n",
    "all_significantly_biased_labels = np.concatenate((np.ones(n, dtype = int),\n",
    "                                                  np.zeros(n, dtype = int)))\n",
    "\n",
    "all_significantly_biased_words, all_significantly_biased_vecs, all_significantly_biased_labels = sklearn.utils.shuffle(\n",
    "all_significantly_biased_words, all_significantly_biased_vecs, all_significantly_biased_labels)\n",
    "#print(np.random.choice(masc_words, size = 75))\n",
    "print(\"TOP MASC:\",masc_words[:50] )\n",
    "print(\"-------------------------\")\n",
    "print(\"TOP FEM:\", fem_words[:50])\n",
    "print(\"-------------------------\")\n",
    "print(\"Random Neutral:\", neut_words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06651511,  0.15298505, -0.22629546,  0.01367087,  0.10383943,\n",
       "        0.19781574,  0.14934979,  0.02839268,  0.19078207, -0.06777252,\n",
       "        0.10532494, -0.11232515,  0.06692035, -0.10428741,  0.06449812,\n",
       "        0.03163765, -0.20662562, -0.00147265,  0.33190876,  0.14005051,\n",
       "       -0.00183823,  0.14094647,  0.00308689,  0.16779467,  0.10143815,\n",
       "        0.18567674, -0.02985709,  0.09640412,  0.06599609, -0.28146555,\n",
       "       -0.09386818,  0.17567203,  0.11368872,  0.05253632, -0.17035815,\n",
       "        0.0029247 ,  0.00165801,  0.06263107,  0.1276077 , -0.07693021,\n",
       "       -0.0652855 , -0.2570974 ,  0.20480825, -0.14751672, -0.0626659 ,\n",
       "        0.00278824,  0.0045029 , -0.34939256,  0.14731076, -0.10574462])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_direction = np.squeeze(gender_direction)\n",
    "bias_direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words considered: 2\n",
      "Running PCA with 1 components\n"
     ]
    }
   ],
   "source": [
    "gender_direction = identify_bias_subspace(\n",
    "    dict_vec_cleaned, def_set_gender, 1, centralizing=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_direction.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 10788; Dev size: 4624; Test size: 6606\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.concatenate((masc_vecs, fem_vecs, neut_vecs), axis = 0)\n",
    "#X = (X - np.mean(X, axis = 0, keepdims = True)) / np.std(X, axis = 0)\n",
    "y_masc = np.ones(masc_vecs.shape[0], dtype = int)\n",
    "y_fem = np.zeros(fem_vecs.shape[0], dtype = int)\n",
    "y_neut = -np.ones(neut_vecs.shape[0], dtype = int)\n",
    "#y = np.concatenate((masc_scores, fem_scores, neut_scores))#np.concatenate((y_masc, y_fem))\n",
    "y = np.concatenate((y_masc, y_fem, y_neut))\n",
    "X_train_dev, X_test, y_train_dev, Y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "X_train, X_dev, Y_train, Y_dev = sklearn.model_selection.train_test_split(X_train_dev, y_train_dev, test_size = 0.3, random_state = 0)\n",
    "print(\"Train size: {}; Dev size: {}; Test size: {}\".format(X_train.shape[0], X_dev.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_clf = LinearSVC\n",
    "#gender_clf = SGDClassifier\n",
    "#gender_clf = LogisticRegression\n",
    "#gender_clf = LinearDiscriminantAnalysis\n",
    "#gender_clf = Perceptron\n",
    "\n",
    "params_svc = {'penalty': 'l2','fit_intercept': False, 'class_weight': None, \"dual\": False, 'random_state': 0}\n",
    "params_sgd = {'penalty': 'l2','fit_intercept': False, 'class_weight': None, 'max_iter': 1000, 'random_state': 0}\n",
    "params = params_svc\n",
    "#params = {'loss': 'hinge', 'n_jobs': 16, 'penalty': 'l2', 'max_iter': 2500, 'random_state': 0}\n",
    "#params = {}\n",
    "n = 35\n",
    "min_acc = 0\n",
    "dropout_rate = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 34, accuracy: 0.972318339100346: 100%|██████████| 35/35 [00:03<00:00,  9.57it/s]\n"
     ]
    }
   ],
   "source": [
    "P, rowspace_projs, Ws = get_debiasing_projection(gender_clf, params, n, 50, min_acc,\n",
    "                                    X_train, Y_train, X_dev, Y_dev, Y_train_main=None, Y_dev_main=None, \n",
    "                                       dropout_rate = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute the gender bias, we need to get the embeddings of \"he\" and \"she\"\n",
    "he_embed = dict_vectors['he']\n",
    "she_embed = dict_vectors['she']\n",
    "\n",
    "# Using the gender bias function to compute the bias of all the words in the limited dataset\n",
    "#We create a dictionary with the word as key and the bias as value\n",
    "gender_bias_original = utils.compute_bias(dict_vec_cleaned, he_embed, she_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_w2i, c_vocab, female_words, male_words, y_true=getting_biased_words(gender_bias_original, def_sets['gender'], 1000, word2idx)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
