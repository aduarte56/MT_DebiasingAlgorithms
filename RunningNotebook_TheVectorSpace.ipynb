{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.ProcessingEmbeddings import *\n",
    "from Scripts.HardDebias import *\n",
    "from Scripts.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec-google-news-300 embeddings\n",
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
      "vectors shape: (3000000, 300), word2idx length: 3000000, vocab length: 3000000\n"
     ]
    }
   ],
   "source": [
    "#glove=Embeddings('glove-wiki-gigaword-50')\n",
    "#glove300=Embeddings('glove-wiki-gigaword-300')\n",
    "word2vec=Embeddings('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=word2vec.vectors\n",
    "word2idx=word2vec.word2idx\n",
    "vocab=word2vec.words\n",
    "dict_vectors = word2vec.get_word_vector_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000000it [07:04, 7064.59it/s]\n"
     ]
    }
   ],
   "source": [
    "word2vec.save_in_word2vec_format(\n",
    "    word2vec.vectors, word2vec.words, 'Data/word2vec-google-news-300.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove3=Embeddings('glove-wiki-gigaword-50.txt', gensim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(vectors).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a limited vocabulary to debias the embeddings.\n",
    "vocab_cleaned, vectors_cleaned, word2idx_cleaned, dict_vec_cleaned = glove3.limit_vocab(vectors, word2idx, vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard-Debias Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender specific vocabulary:\n",
    "gender_specific=[]\n",
    "female_vocab=[]\n",
    "male_vocab=[]\n",
    "with open('./Data/male_word_file.txt') as f:\n",
    "    male_vocab = [line.strip() for line in f]\n",
    "\n",
    "with open('./Data/female_word_file.txt') as f:\n",
    "    for l in f:\n",
    "        female_vocab.append(l.strip())\n",
    "\n",
    "gender_specific=female_vocab+female_vocab\n",
    "\n",
    "with codecs.open('./Data/gender_specific_full.json') as f:\n",
    "    gender_specific.extend(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the definitional sets to calculate afterwards the gender direction. The first 10 gender sets were proposed by Bolukbasi et al. (2016)\n",
    "#Definitional sets for race where proposed by Manzini et al. in Multiclass debiasing of embeddings: https://github.com/TManzini/DebiasMulticlassWordEmbedding/blob/master/Debiasing/data/vocab/race_attributes_optm.json\n",
    "\n",
    "def_sets = {\n",
    "    \"gender\": [\n",
    "        ['she', 'he'], ['herself', 'himself'], [\n",
    "            'her', 'his'], ['daughter', 'son'], ['girl', 'boy'],\n",
    "        ['mother', 'father'], ['woman', 'man'], ['mary', 'john'], ['gal', 'guy'], ['female', 'male'], ['aunt', 'uncle']],\n",
    "\n",
    "    \"race\": [\n",
    "        [\"black\", \"caucasian\", \"asian\", \"hispanic\"],\n",
    "      \t\t[\"african\", \"caucasian\", \"asian\", \"hispanic\"],\n",
    "      \t\t[\"black\", \"white\", \"asian\", \"latino\"],\n",
    "      \t\t[\"africa\", \"europe\", \"asia\", \"mexico\"],\n",
    "      \t\t[\"africa\", \"america\", \"china\", \"latin-america\"],\n",
    "    ]\n",
    "}\n",
    "\n",
    "#Equalizing pairs for gender debiasing were first published by Bolukbasi et al. in https://github.com/tolga-b/debiaswe/blob/master/data/equalize_pairs.json\n",
    "# Equalizing sets for race where defined by Manzini as equal to the defining set (Manzini et al., 2019.p.3)\n",
    "equalizing_lists = {\n",
    "    \"gender\": [\n",
    "        [\"monastery\", \"convent\"], [\"spokesman\", \"spokeswoman\"], [\n",
    "            \"Catholic_priest\", \"nun\"], [\"Dad\", \"Mom\"], [\"Men\", \"Women\"],\n",
    "        [\"councilman\", \"councilwoman\"], [\"grandpa\", \"grandma\"], [\n",
    "            \"grandsons\", \"granddaughters\"], [\"prostate_cancer\", \"ovarian_cancer\"],\n",
    "        [\"testosterone\", \"estrogen\"], [\"uncle\", \"aunt\"], [\n",
    "            \"wives\", \"husbands\"], [\"Father\", \"Mother\"], [\"Grandpa\", \"Grandma\"],\n",
    "        [\"He\", \"She\"], [\"boy\", \"girl\"], [\"boys\", \"girls\"], [\"brother\", \"sister\"], [\n",
    "            \"brothers\", \"sisters\"], [\"businessman\", \"businesswoman\"],\n",
    "        [\"chairman\", \"chairwoman\"], [\"colt\", \"filly\"], [\"congressman\",\n",
    "                                                        \"congresswoman\"], [\"dad\", \"mom\"], [\"dads\", \"moms\"], [\"dudes\", \"gals\"],\n",
    "        [\"ex_girlfriend\", \"ex_boyfriend\"], [\"father\", \"mother\"], [\n",
    "            \"fatherhood\", \"motherhood\"], [\"fathers\", \"mothers\"], [\"fella\", \"granny\"],\n",
    "        [\"fraternity\", \"sorority\"], [\"gelding\", \"mare\"], [\"gentleman\", \"lady\"], [\n",
    "            \"gentlemen\", \"ladies\"], [\"grandfather\", \"grandmother\"],\n",
    "        [\"grandson\", \"granddaughter\"], [\"he\", \"she\"], [\"himself\", \"herself\"], [\n",
    "            \"his\", \"her\"], [\"king\", \"queen\"], [\"kings\", \"queens\"],\n",
    "        [\"male\", \"female\"], [\"males\", \"females\"], [\"man\", \"woman\"], [\n",
    "            \"men\", \"women\"], [\"nephew\", \"niece\"], [\"prince\", \"princess\"],\n",
    "        [\"schoolboy\", \"schoolgirl\"], [\"son\", \"daughter\"], [\"sons\", \"daughters\"], [\"twin_brother\", \"twin_sister\"]]}\n",
    "\n",
    "#Some of the words were taken from the analogies' templates from Cheng and Manzini.\n",
    "#The list is not the same, however, because some of the words were not neutral, but carried some\n",
    "#relation to the social categories.\n",
    "neutral_words = [\"manager\", \"executive\", \"doctor\", \"lawyer\", \"programmer\",\n",
    "                 \"scientist\", \"soldier\", \"supervisor\", \"rancher\", \"janitor\",\n",
    "                 \"firefighter\", \"officer\", \"secretary\", \"nurse\", \"clerk\", \"artist\",\n",
    "                 \"homemaker\", \"dancer\", \"singer\", \"librarian\", \"maid\", \"hairdresser\", \"stylist\",\n",
    "                 \"receptionist\", \"counselor\", \"leader\", \"farmer\",\n",
    "                 \"engineer\", \"laborer\", \"teacher\",\n",
    "                 \"slave\", \"musician\", \"runner\", \"criminal\", \"homeless\",\n",
    "                 \"greedy\", \"cheap\", \"hairy\", \"liberal\",\n",
    "                 \"judgemental\", \"conservative\", \"familial\",\n",
    "                 \"violent\", \"terrorist\", \"dirty\", \"uneducated\", \"educated\"]\n",
    "\n",
    "\n",
    "#However, also the vocabulary without the gendered words from the list can be conceived as neutral, according to Bolukbasi et al.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lists of names for validation\n",
    "#Adapted from Speer's tutorial on racism in sentiment analysis. http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/\n",
    "names_ethnicity = {\n",
    "    # The first two lists are from the Caliskan et al. appendix describing the\n",
    "    # Word Embedding Association Test.\n",
    "    'White': [\n",
    "        'Adam', 'Chip', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Ian', 'Justin',\n",
    "        'Ryan', 'Andrew', 'Fred', 'Jack', 'Matthew', 'Stephen', 'Brad', 'Greg', 'Jed',\n",
    "        'Paul', 'Todd', 'Brandon', 'Hank', 'Jonathan', 'Peter', 'Wilbur', 'Amanda',\n",
    "        'Courtney', 'Heather', 'Melanie', 'Sara', 'Amber', 'Crystal', 'Katie',\n",
    "        'Meredith', 'Shannon', 'Betsy', 'Donna', 'Kristin', 'Nancy', 'Stephanie',\n",
    "        'Bobbie-Sue', 'Ellen', 'Lauren', 'Peggy', 'Sue-Ellen', 'Colleen', 'Emily',\n",
    "        'Megan', 'Rachel', 'Wendy'\n",
    "    ],\n",
    "\n",
    "    'Black': [\n",
    "        'Alonzo', 'Jamel', 'Lerone', 'Percell', 'Theo', 'Alphonse', 'Jerome',\n",
    "        'Leroy', 'Rasaan', 'Torrance', 'Darnell', 'Lamar', 'Lionel', 'Rashaun',\n",
    "        'Tyree', 'Deion', 'Lamont', 'Malik', 'Terrence', 'Tyrone', 'Everol',\n",
    "        'Lavon', 'Marcellus', 'Terryl', 'Wardell', 'Aiesha', 'Lashelle', 'Nichelle',\n",
    "        'Shereen', 'Temeka', 'Ebony', 'Latisha', 'Shaniqua', 'Tameisha', 'Teretha',\n",
    "        'Jasmine', 'Latonya', 'Shanise', 'Tanisha', 'Tia', 'Lakisha', 'Latoya',\n",
    "        'Sharise', 'Tashika', 'Yolanda', 'Lashandra', 'Malika', 'Shavonn',\n",
    "        'Tawanda', 'Yvette'\n",
    "    ],\n",
    "\n",
    "    # This list comes from statistics about common Hispanic-origin names in the US.\n",
    "    'Hispanic': [\n",
    "        'Juan', 'José', 'Miguel', 'Luís', 'Jorge', 'Santiago', 'Matías', 'Sebastián',\n",
    "        'Mateo', 'Nicolás', 'Alejandro', 'Samuel', 'Diego', 'Daniel', 'Tomás',\n",
    "        'Juana', 'Ana', 'Luisa', 'María', 'Elena', 'Sofía', 'Isabella', 'Valentina',\n",
    "        'Camila', 'Valeria', 'Ximena', 'Luciana', 'Mariana', 'Victoria', 'Martina'\n",
    "    ],\n",
    "\n",
    "\n",
    "}\n",
    "#Following Bolukbasi et al. Implementing notebook: https://github.com/tolga-b/debiaswe/blob/master/tutorial_example1.ipynb\n",
    "names = [\"Emily\", \"Aisha\", \"Anne\", \"Keisha\", \"Jill\", \"Tamika\", \"Allison\", \"Lakisha\", \"Laurie\", \"Tanisha\", \"Sarah\",\n",
    "         \"Latoya\", \"Meredith\", \"Kenya\", \"Carrie\", \"Latonya\", \"Kristen\", \"Ebony\", \"Todd\", \"Rasheed\", \"Neil\", \"Tremayne\",\n",
    "         \"Geoffrey\", \"Kareem\", \"Brett\", \"Darnell\", \"Brendan\", \"Tyrone\", \"Greg\", \"Hakim\", \"Matthew\", \"Jamal\", \"Jay\",\n",
    "         \"Leroy\", \"Brad\", \"Jermaine\"]\n",
    "#names_group1 = [names[2 * i] for i in range(len(names) // 2)]\n",
    "#names_group2 = [names[2 * i + 1] for i in range(len(names) // 2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euroam_names = [\"Adam\", \"Alan\", \"Allison\", \"Amanda\", \"Amber\", \"Andrew\", \"Anne\", \"Betsy\", \"Bobbie-Sue\", \"Brad\", \"Brandon\", \"Brendan\", \"Brett\", \"Carrie\", \"Chip\", \"Colleen\", \"Courtney\", \"Crystal\", \"Donna\", \"Ellen\", \"Emily\", \"Frank\", \"Fred\", \"Geoffrey\", \"Greg\", \"Hank\", \"Harry\", \"Heather\", \"Ian\", \"Jack\", \"Jay\",\n",
    "                \"Jed\", \"Jill\", \"Jonathan\", \"Josh\", \"Justin\", \"Katie\", \"Kristen\", \"Kristin\", \"Lauren\", \"Laurie\", \"Matthew\", \"Megan\", \"Melanie\", \"Meredith\", \"Nancy\", \"Neil\", \"Neil\", \"Paul\", \"Peggy\", \"Peter\", \"Rachel\", \"Roger\", \"Ryan\", \"Sara\", \"Sarah\", \"Shannon\", \"Stephanie\", \"Stephen\", \"Sue-Ellen\", \"Todd\", \"Wendy\", \"Wilbur\"]\n",
    "\n",
    "africanam_names = [\"Aiesha\", \"Aisha\", \"Alonzo\", \"Alphonse\", \"Darnell\", \"Deion\", \"Ebony\", \"Everol\", \"Hakim\", \"Jamal\", \"Jamel\", \"Jasmine\", \"Jermaine\", \"Jerome\", \"Kareem\", \"Keisha\", \"Kenya\", \"Lakisha\", \"Lamar\", \"Lamont\", \"Lashandra\", \"Lashelle\", \"Latisha\", \"Latonya\", \"Latoya\", \"Lavon\", \"Lerone\", \"Leroy\", \"Lionel\", \"Malik\", \"Malika\", \"Marcellus\", \"Nichelle\", \"Percell\", \"Rasaan\", \"Rashaun\", \"Rasheed\", \"Shaniqua\", \"Shanise\", \"Sharise\", \"Shavonn\", \"Shereen\", \"Tameisha\", \"Tamika\", \"Tanisha\",\n",
    "                   \"Tashika\", \"Tawanda\", \"Temeka\", \"Teretha\", \"Terrence\", \"Terryl\", \"Theo\", \"Tia\", \"Torrance\", \"Tremayne\", \"Tyree\", \"Tyrone\", \"Wardell\", \"Yolanda\", \"Yvette\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to prepare the def_set_lists for the debiasing\n",
    "def prepare_def_sets_subspace(list_def_sets):\n",
    "  def_sets={i: v for i, v in enumerate(list_def_sets)}\n",
    "  return def_sets\n",
    "\n",
    "def_set_gender=utils.prepare_def_sets_subspace(def_sets[\"gender\"])\n",
    "def_set_race=utils.prepare_def_sets_subspace(def_sets[\"race\"])\n",
    "def_set_joined=utils.prepare_def_sets_subspace(def_sets[\"gender\"]+ def_sets[\"race\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalizing_lists['race']=get_pairs_from_equalizing_sets(def_sets['race'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalizing_lists['intersection']=get_pairs(def_sets['gender'], def_sets['race'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deb_vect_gender, deb_vocab_gender, deb_word2idx_gender,deb_dict_gender = hard_debias(vectors,\n",
    "                             dict_vectors, \n",
    "                             word2idx_cleaned,\n",
    "                             vocab_cleaned, \n",
    "                             equalizing_lists['gender'], \n",
    "                             def_set_gender,\n",
    "                             1,\n",
    "                             normalize_dir=False,\n",
    "                             normalize=None,\n",
    "                             centralizing=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deb_vect_joined, deb_vocab_joined, deb_word2idx_joined, deb_dict_joined = hard_debias(vectors,\n",
    "                                                                            dict_vectors,\n",
    "                                                                              word2idx_cleaned,\n",
    "                                                                              vocab_cleaned,\n",
    "                                                                              equalizing_lists['intersection'],\n",
    "                                                                              def_set_joined,\n",
    "                                                                              1,\n",
    "                                                                              normalize_dir=False,\n",
    "                                                                              normalize=None,\n",
    "                                                                              centralizing=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Visualization import *\n",
    "from Scripts.Evaluation import *\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_term_analogies(dict_vectors, 'man', 'programmer', 'woman', include_triplet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_term_analogies(dict_vec_cleaned, 'cloud',\n",
    "                   'clouds', 'drink', include_triplet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.model.most_similar(\n",
    "    positive=['man', 'programmer'], negative=[\"woman\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_term_analogies(dict_vec_cleaned, 'France', 'Paris', 'Japan')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender Bias Pre-Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute the gender bias, we need to get the embeddings of \"he\" and \"she\"\n",
    "he_embed = dict_vectors['he']\n",
    "she_embed = dict_vectors['she']\n",
    "\n",
    "# Using the gender bias function to compute the bias of all the words in the limited dataset\n",
    "#We create a dictionary with the word as key and the bias as value\n",
    "gender_bias_original = compute_gender_simple_bias(dict_vec_cleaned, he_embed, she_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_direction = identify_bias_subspace(\n",
    "    dict_vectors, def_set_gender, 1, centralizing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_original2 = compute_direct_bias(\n",
    "    dict_vectors, vocab_cleaned, gender_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_average_bias(deb_dict_gender, neutral_words, gender_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_original2 = compute_direct_bias(\n",
    "    deb_dict_gender, neutral_words, gender_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_after_debiasing=compute_gender_simple_bias(deb_dict_gender, he_embed, she_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations = ['assistant','secretary','data scientist', 'scientist', 'politician','janitor', 'hairdresser','teacher', 'bartender','midwife','doctor','ballerina','dancer','pediatrician','surgeon', 'physician', 'shopkeeper',  'nurse', 'interior designer', 'architect', 'maid', 'housekeeper', 'soprano', 'baritone', 'servant',  'vocalists', 'guitarists','carpenter','clerk','manager','supervisor','driver','software developer','lawyer','pitcher', 'bookkeeper', 'infielder', 'receptionist', 'investigator', 'pundit', 'chancellor', 'maestro','lecturer','salesperson','homemaker', 'receptionist','librarian', 'nanny', 'bookkeeper', 'stylist','housekeeper','guidance counselor','skipper', 'protege','philosopher','captain', 'architect', 'financier', 'warrior', 'broadcaster', 'magician', 'figher','pilot', 'boss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_df=get_bias_score_df_from_list(gender_bias_original,gender_bias_after_debiasing, occupations,vocab_cleaned,deb_vocab_gender)\n",
    "plot_bias_bar(bias_df, \"Gender bias on occupations (original vs debiased)\", \"Occupations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_w2i, c_vocab, female_words, male_words, y_true=getting_biased_words(gender_bias_original, def_sets['gender'], 1000, word2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendered_vectors=utils.extract_vectors(male_words + female_words, vectors_cleaned, word2idx_cleaned)\n",
    "cluster_and_visualize(male_words + female_words,\n",
    "                      gendered_vectors, 'GloVe_original', y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendered_debiased_vectors = utils.extract_vectors(\n",
    "    male_words + female_words, deb_vect_gender, deb_word2idx_gender)\n",
    "\n",
    "cluster_and_visualize(male_words + female_words, gendered_debiased_vectors,\n",
    "                      'Debiased_GloVe', y_true)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Random Words: bias scores and neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "#set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "#choosing random words from the vocabulary\n",
    "random_words = np.random.choice(vocab_cleaned[:10000], size=50)\n",
    "\n",
    "#setting parameters for the gensim method \"most_similar\"\n",
    "topn = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the gender bias score for the random words list\n",
    "bias_df = get_bias_score_df_from_list(\n",
    "    gender_bias_original, gender_bias_after_debiasing, random_words, vocab_cleaned, deb_vocab_gender)\n",
    "plot_bias_bar(\n",
    "    bias_df, \"Gender bias on random_words (original vs debiased)\", \"Random_words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity checks\n",
    "#Gensim's .most_similar() method finds the top-N most similar words to a given word.\n",
    "#See documentation: https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.most_similar.html\n",
    "glove.model.most_similar(random_words[0], topn=10)\n",
    "model_original = create_KeyedVectors(vectors_cleaned, vocab_cleaned, 50)\n",
    "model_original.most_similar(random_words[0], topn=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topK_neighbors(random_words[0], dict_vec_cleaned,\n",
    "                   vocab_cleaned, vectors_cleaned, word2idx_cleaned, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neigh= get_k_nearest_neighbors(random_words, dict_vec_cleaned, vocab_cleaned, vectors_cleaned, word2idx_cleaned, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_neigh = get_list_neighbors(k_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neig_freq2=get_frequency_original_neighbors(\n",
    "    random_words, list_neigh, deb_dict_gender, deb_vocab_gender, deb_vect_gender, deb_word2idx_gender, neighbours_num=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(neig_freq2, columns=['word', 'previous_neighbours', 'freq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px\n",
    "#plot the frequency of the original neighbours in the debiased network in a horizontal bar chart\n",
    "\n",
    "fig = px.bar(df, x='word', y='freq', title='Proportion of original 50 neighbours in the debiased k-vicinity of each word',\n",
    "             labels={'freq':'Proportion', 'word':'Word'},\n",
    "             height=500, width=1000)\n",
    "#update the layout of the plot: update the y axis to be between 0 and 0.5 and the x axis to include all ticks\n",
    "fig.update_layout(yaxis=dict(range=[0, 0.5]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the neighbors of debiased vectors the Gensim way\n",
    "gender_debiased = create_KeyedVectors(deb_vect_gender, deb_vocab_gender, 50)\n",
    "finding_neighbors_before_after(random_words, model_original, gender_debiased, topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neigh= get_k_nearest_neighbors(random_words, deb_dict_gender, deb_vocab_gender, deb_vect_gender, deb_word2idx_gender, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "from Scripts.Visualization import tsne_plot_similar_words\n",
    "\n",
    "#This approach was inspired by the following blog post:https://towardsdatascience.com/google-news-and-leo-tolstoy-visualizing-word2vec-word-embeddings-with-t-sne-11558d8bd4d\n",
    "keys = random_words\n",
    "embedding_clusters, db_embedding_clusters, word_clusters = get_embeddings_neighbors(\n",
    "    keys, model_original, gender_debiased, 50)\n",
    "\n",
    "n, m, k = embedding_clusters.shape\n",
    "tsne_model_en_2d = TSNE(perplexity=2, n_components=2,\n",
    "                        init='pca', n_iter=3500, random_state=42)\n",
    "embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(\n",
    "    embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "db_embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(\n",
    "    db_embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot_similar_words('Similar words before Debiasing',\n",
    "                        keys, embeddings_en_2d, word_clusters, 0.7)\n",
    "tsne_plot_similar_words('Similar words after Debiasing',\n",
    "                        keys, db_embeddings_en_2d, word_clusters, 0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_original,distances_debiased=get_distance_to_neighbors(random_words, list_neigh,\n",
    "                          dict_vec_cleaned, deb_dict_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataframe of distances from distances_original and distances_debiased\n",
    "def get_df_distances(distances_original,distances_debiased):\n",
    "    df=pd.DataFrame()\n",
    "    for word in distances_original.keys():\n",
    "        for i in range(len(distances_original[word])):\n",
    "            #df=df.append({'word':word, 'neighbor':distances_original[word][i][0], 'distance_original':distances_original[word][i][1], 'distance_debiased':distances_debiased[word][i][1]}, ignore_index=True)\n",
    "            df=pd.concat([df, pd.DataFrame.from_records([{'word':word, 'neighbor':distances_original[word][i][0], 'distance_original':distances_original[word][i][1], 'distance_debiased':distances_debiased[word][i][1]}])], ignore_index=True)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neigh_distances=get_df_distances(distances_original,distances_debiased)\n",
    "\n",
    "#use df_neigh_distances to get the average distance original and distance debiased for each word using pandas\n",
    "df_average=df_neigh_distances[['word', 'distance_original', 'distance_debiased']].groupby('word').mean()\n",
    "\n",
    "#now add a column of the difference between the two mean distances\n",
    "df_average['difference']=abs(df_average['distance_original']-df_average['distance_debiased'])\n",
    "\n",
    "df_average=df_average.sort_values(by='difference', ascending=True)\n",
    "df_average=df_average.rename(columns={'distance_original':'average distance to neighbors (original embeddings)', 'distance_debiased':'average distance to neighbors (debiased embeddings)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the average distance to neighbors before and after debiasing\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=df_average.index, y=df_average['average distance to neighbors (original embeddings)'], name='Original Embeddings'))\n",
    "fig.add_trace(go.Bar(x=df_average.index, y=df_average['average distance to neighbors (debiased embeddings)'], name='Debiased Embeddings'))\n",
    "#add title\n",
    "fig.update_layout(title_text='Average cosine distance to neighbors before and after debiasing')\n",
    "#change x axis title\n",
    "fig.update_xaxes(title_text='Words Chosen at Random')\n",
    "#change y axis title\n",
    "fig.update_yaxes(title_text='Average Cosine Distance to Neighbors')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_direction = identify_bias_subspace(\n",
    "    deb_dict_gender, def_set_race, 1, centralizing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_original2 = compute_direct_bias(\n",
    "    deb_dict_gender, neutral_words, race_direction)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_white= list(w.lower() for w in names_ethnicity['White'] if w.lower() in set(vocab_cleaned))\n",
    "names_black= list(w.lower() for w in names_ethnicity['Black'] if w.lower() in set(vocab_cleaned))\n",
    "names_latino= list(w.lower() for w in names_ethnicity['Hispanic'] if w.lower() in set(vocab_cleaned))\n",
    "#euroam_names_emb= list(w for w in euroam_names if w in set(vocab_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_df_names = get_bias_score_df_from_list(\n",
    "    gender_bias_original, gender_bias_after_debiasing, names_black, vocab_cleaned, deb_vocab_gender)\n",
    "plot_bias_bar(\n",
    "    bias_df_names, \"Gender bias on english names (original vs debiased)\", \"Names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neigh= get_k_nearest_neighbors(names_black[:17], dict_vec_cleaned, vocab_cleaned, vectors_cleaned, word2idx_cleaned, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_neigh = get_list_neighbors(k_neigh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_frequency_original_neighbors(\n",
    "    names_black[:17], list_neigh, deb_dict_gender, deb_vocab_gender, deb_vect_gender, deb_word2idx_gender, neighbours_num=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_debiased = create_KeyedVectors(deb_vect_gender, deb_vocab_gender, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendered_words_before_and_after=finding_neighbors_before_after(names_black, model_original, model_debiased, topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys2=names_black\n",
    "embedding_clusters, db_embedding_clusters, word_clusters = get_embeddings_neighbors(keys2, model_original, model_debiased, topn)\n",
    "\n",
    "n, m, k = embedding_clusters.shape\n",
    "tsne_model_en_2d = TSNE(perplexity=2, n_components=2,\n",
    "                        init='pca', n_iter=3500, random_state=32)\n",
    "embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(\n",
    "    embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "db_embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(\n",
    "    db_embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "\n",
    "\n",
    "tsne_plot_similar_words('Similar words before Debiasing', keys2, embeddings_en_2d, word_clusters, 0.7)\n",
    "tsne_plot_similar_words('Similar words after Debiasing',\n",
    "                        keys2, db_embeddings_en_2d, word_clusters, 0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tuples of biases and counts of masculine/feminine NN for each word (for bias-by-neighbors)\n",
    "\n",
    "def bias_by_neighbors(dict_vect, vocab, vectors, w2i, neighbours_num=100):\n",
    "\n",
    "    tuples = []\n",
    "    for word in tqdm(vocab):\n",
    "\n",
    "        _, top = topK(word, dict_vect, vocab, vectors, w2i,\n",
    "                      k=neighbours_num+5)\n",
    "\n",
    "        m = 0\n",
    "        f = 0\n",
    "        for t in top:\n",
    "            if gender_bias_original[t] < 0:\n",
    "                m += 1\n",
    "            else:\n",
    "                f += 1\n",
    "\n",
    "        tuples.append(\n",
    "            (word, gender_bias_original[word], gender_bias_after_debiasing[word], m, f))\n",
    "\n",
    "    return tuples\n",
    "\n",
    "\n",
    "bias_by_neighbors(dict_vec_cleaned, vocab_cleaned,\n",
    "                  vectors_cleaned, word2idx_cleaned, neighbours_num=50)\n",
    "\n",
    "gendered_names = [\"ruth\", \"charlotte\", \"abigail\", \"sophie\", \"nichole\",\n",
    "                  \"emma\", \"olivia\", \"ava\", \"isabella\", \"sophia\", \"charlotte\", \"mia\", \"amelia\"]\n",
    "# \"james\", \"john\", \"robert\", \"michael\", \"william\", \"david\", \"richard\", \"joseph\", \"thomas\", \"ariel\", \"mike\", \"nurse\", \"secretary\", \"nursery\"]\n",
    "#words_chosen = [\"miss\", \"mrs\", \"mr\", \"john\", \"rachel\",\n",
    "# \"wife\", \"mom\", \"family\", \"father\", \"lady\", \"he\", \"she\"]\n",
    "\n",
    "gendered_words_before_and_after = finding_neighbors_before_after(\n",
    "    gendered_names, model_original, model_debiased, topn=3)\n",
    "keys2 = gendered_names\n",
    "embedding_clusters, db_embedding_clusters, word_clusters = get_embeddings_neighbors(\n",
    "    keys2, model_original, model_debiased, topn)\n",
    "\n",
    "n, m, k = embedding_clusters.shape\n",
    "tsne_model_en_2d = TSNE(perplexity=2, n_components=2,\n",
    "                        init='pca', n_iter=3500, random_state=32)\n",
    "embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(\n",
    "    embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "db_embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(\n",
    "    db_embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "\n",
    "\n",
    "tsne_plot_similar_words('Similar words before Debiasing',\n",
    "                        keys2, embeddings_en_2d, word_clusters, 0.7)\n",
    "tsne_plot_similar_words('Similar words after Debiasing',\n",
    "                        keys2, db_embeddings_en_2d, word_clusters, 0.7)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [[\"he\", \"she\"],\n",
    "            [\"his\", \"hers\"],\n",
    "            [\"son\", \"daughter\"],\n",
    "            [\"father\", \"mother\"],\n",
    "            [\"male\", \"female\"],\n",
    "            [\"boy\", \"girl\"],\n",
    "            [\"uncle\", \"aunt\"]]\n",
    "\n",
    "Attribtutes = [[\"manager\", \"executive\", \"doctor\", \"lawyer\", \"programmer\", \"scientist\",\n",
    "                \"soldier\", \"supervisor\", \"rancher\", \"janitor\", \"firefighter\", \"officer\"], [\"secretary\", \"nurse\", \"clerk\", \"artist\", \"homemaker\", \"dancer\", \"singer\", \"librarian\", \"maid\", \"hairdresser\", \"stylist\", \"receptionist\", \"counselor\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiasedMAC, debiasedDistribution=multiclass_evaluation_MAC(\n",
    "    debiased_dict, targets, Attribtutes)\n",
    "\n",
    "originalMAC,originalDistribution = multiclass_evaluation_MAC(\n",
    "    dict_vec_cleaned, targets, Attribtutes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel, spearmanr\n",
    "statistics, pvalue = ttest_rel(originalDistribution, debiasedDistribution)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias by neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_w2i, c_vocab, female_words, male_words, y_true=getting_biased_words(\n",
    "    gender_bias_original, def_sets['gender'], 1000, word2idx_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_words=female_words+male_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "k_neighbors=finding_neighbors_before_after(\n",
    "    biased_words, model_original, model_debiased, topn=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take k_neighbors dictionary and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_bias_by_clustering(model_original, model_debiased, biased_words, 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deb_vect_race, deb_vocab_race, deb_word2idx_race, deb_dict_race = hard_debias(vectors,\n",
    "                                                                              dict_vectors,\n",
    "                                                                              word2idx_cleaned,\n",
    "                                                                              vocab_cleaned,\n",
    "                                                                              equalizing_lists['race'],\n",
    "                                                                              def_set_race,\n",
    "                                                                              1,\n",
    "                                                                              normalize_dir=False,\n",
    "                                                                              normalize=None,\n",
    "                                                                              centralizing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neig_freq_race= get_frequency_original_neighbors(\n",
    "    random_words, list_neigh, deb_dict_race, deb_vocab_race, deb_vect_race, deb_word2idx_race, neighbours_num=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(neig_freq_race, columns=['word', 'previous_neighbours', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding race Debiased Words.\n",
    "race_debiased = create_KeyedVectors(deb_vect_race, deb_vocab_race, 50)\n",
    "finding_neighbors_before_after(random_words, model_original, race_debiased, topn=3)\n",
    "joined_debiased = create_KeyedVectors(deb_vect_joined, deb_vocab_joined, 50)\n",
    "finding_neighbors_before_after(\n",
    "    random_words, model_original, joined_debiased, topn=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Embeddings on a txt file.\n",
    "- And loading them as a Gensim model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the debiased vectors and vocab to a text file\n",
    "glove.save_in_word2vec_format(\n",
    "    debiased_vectors, debiased_vocab, \"./Data/vecs.50.cleaned.txt\")\n",
    "\n",
    "#Loading the vectors into a KeyedVectors object 'model_cleaned' that we can use to find the most similar words to a given word\n",
    "model_cleaned, _, _ = load_word_vectors(\n",
    "    fname=\"./Data/vecs.50.cleaned.txt\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.INLP import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_original = create_KeyedVectors(vectors_cleaned, vocab_cleaned, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vectors_per_class = 7500\n",
    "\n",
    "gender_direction = identify_bias_subspace(\n",
    "    dict_vec_cleaned, def_set_gender, 1, centralizing=False)\n",
    "gender_direction = np.squeeze(gender_direction)\n",
    "\n",
    "gender_unit_vec = gender_direction/np.linalg.norm(gender_direction)\n",
    "fem_words_and_scores, masc_words_and_scores, neut_words_and_scores = getting_classes_for_INLP(\n",
    "    gender_vector=gender_direction, model=model_original, n=7500)\n",
    "\n",
    "masc_words, masc_scores = list(zip(*masc_words_and_scores))\n",
    "neut_words, neut_scores = list(zip(*neut_words_and_scores))\n",
    "fem_words, fem_scores = list(zip(*fem_words_and_scores))\n",
    "\n",
    "#getting the vectors corresponding to masc_words from the dict_vec_cleaned\n",
    "masc_vecs = [vector for word, vector in dict_vec_cleaned.items()\n",
    "             if word in masc_words]\n",
    "fem_vecs = [vector for word, vector in dict_vec_cleaned.items()\n",
    "            if word in fem_words]\n",
    "neut_vecs = [vector for word, vector in dict_vec_cleaned.items()\n",
    "             if word in neut_words]\n",
    "\n",
    "#turn the list of vectors into a numpy array\n",
    "masc_vecs = np.array(masc_vecs)\n",
    "fem_vecs = np.array(fem_vecs)\n",
    "neut_vecs = np.array(neut_vecs)\n",
    "\n",
    "#masc_vecs, fem_vecs = model_original.get_vectors_from_list(masc_words), model_original.get_vectors_from_list(fem_words)\n",
    "#neut_vecs = model_original.get_vectors_from_list(neut_words)\n",
    "\n",
    "n = min(3000, num_vectors_per_class)\n",
    "all_significantly_biased_words = masc_words[:n] + fem_words[:n]\n",
    "all_significantly_biased_vecs = np.concatenate((masc_vecs[:n], fem_vecs[:n]))\n",
    "all_significantly_biased_labels = np.concatenate((np.zeros(n, dtype=int),\n",
    "                                                  np.ones(n, dtype=int)))\n",
    "\n",
    "all_significantly_biased_words, all_significantly_biased_vecs, all_significantly_biased_labels = sklearn.utils.shuffle(\n",
    "    all_significantly_biased_words, all_significantly_biased_vecs, all_significantly_biased_labels)\n",
    "#print(np.random.choice(masc_words, size = 75))\n",
    "print(\"TOP MASC:\", masc_words[:50])\n",
    "print(\"-------------------------\")\n",
    "print(\"TOP FEM:\", fem_words[:50])\n",
    "print(\"-------------------------\")\n",
    "print(\"Random Neutral:\", neut_words[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.seed(42)\n",
    "#np.random.seed(42)\n",
    "\n",
    "X = np.concatenate((masc_vecs, fem_vecs, neut_vecs), axis=0)\n",
    "#X = (X - np.mean(X, axis = 0, keepdims = True)) / np.std(X, axis = 0)\n",
    "y_masc = np.ones(masc_vecs.shape[0], dtype=int)\n",
    "y_fem = np.zeros(fem_vecs.shape[0], dtype=int)\n",
    "y_neut = -np.ones(neut_vecs.shape[0], dtype=int)\n",
    "#y = np.concatenate((masc_scores, fem_scores, neut_scores))#np.concatenate((y_masc, y_fem))\n",
    "y = np.concatenate((y_masc, y_fem, y_neut))\n",
    "X_train_dev, X_test, y_train_dev, Y_test = sklearn.model_selection.train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_dev, Y_train, Y_dev = sklearn.model_selection.train_test_split(\n",
    "    X_train_dev, y_train_dev, test_size=0.3, random_state=42)\n",
    "print(\"Train size: {}; Dev size: {}; Test size: {}\".format(\n",
    "    X_train.shape[0], X_dev.shape[0], X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "gender_clf = LinearSVC\n",
    "#gender_clf = SGDClassifier\n",
    "#gender_clf = LogisticRegression\n",
    "#gender_clf = LinearDiscriminantAnalysis\n",
    "#gender_clf = Perceptron\n",
    "\n",
    "params_svc = {'penalty': 'l2', 'fit_intercept': False,\n",
    "              'class_weight': None, \"dual\": False, 'random_state': 42}\n",
    "params_sgd = {'penalty': 'l2', 'fit_intercept': False,\n",
    "              'class_weight': None, 'max_iter': 1000, 'random_state': 42}\n",
    "params = params_svc\n",
    "#params = {'loss': 'hinge', 'n_jobs': 16, 'penalty': 'l2', 'max_iter': 2500, 'random_state': 0}\n",
    "#params = {}\n",
    "n = 35\n",
    "min_acc = 0\n",
    "dropout_rate = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P, rowspace_projs, Ws = get_debiasing_projection(gender_clf, params, n, 50, min_acc,\n",
    "                                                 X_train, Y_train, X_dev, Y_dev,\n",
    "                                                 is_autoregressive=True, Y_train_main=None, Y_dev_main=None,\n",
    "                                                 dropout_rate=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlp_vectors = (P.dot(vectors_cleaned.T)).T\n",
    "inlp_dict = get_debiased_dict(inlp_vectors, word2idx_cleaned)\n",
    "inlp_vocab = list(inlp_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlp_freq=get_frequency_original_neighbors(\n",
    "    random_words, list_neigh, inlp_dict, inlp_vocab, inlp_vectors, word2idx_cleaned, neighbours_num=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlp_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px\n",
    "df2=pd.DataFrame(inlp_freq, columns=['word', 'previous_neighbours', 'freq'])\n",
    "\n",
    "#plot the frequency of the original neighbours in the debiased network in a horizontal bar chart\n",
    "\n",
    "fig = px.bar(df2, x='word', y='freq', title='Proportion of original 50 neighbours in the debiased network',\n",
    "             labels={'freq': 'Proportion', 'word': 'Word'},\n",
    "             height=500, width=1000)\n",
    "#update the layout of the plot: update the y axis to be between 0 and 0.5 and the x axis to include all ticks\n",
    "fig.update_layout(yaxis=dict(range=[0, 0.5]))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_original_inlp, distances_debiased_inlp = get_distance_to_neighbors(random_words, list_neigh,\n",
    "                                                                   dict_vec_cleaned, inlp_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_df3 = get_bias_score_df_from_list(\n",
    "    gender_bias_original, gender_bias_after_debiasing, random_words, vocab_cleaned, deb_vocab_gender)\n",
    "plot_bias_bar(\n",
    "    bias_df3, \"Gender bias on occupations (original vs debiased)\", \"Occupations\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Bias Direction from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dir=identify_bias_subspace(dict_vec_cleaned, def_set_gender, 1, centralizing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dir = np.squeeze(gender_dir)\n",
    "gender_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dir=identify_bias_subspace(dict_vec_cleaned, def_set_race, 1, centralizing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dir = np.squeeze(race_dir)\n",
    "race_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_gender=neutralize_words(vocab_cleaned, vectors, word2idx_cleaned, gender_dir)\n",
    "wv_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalize_words(wv_gender, vocab_cleaned, word2idx_cleaned,\n",
    "               equalizing_lists['gender'], gender_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_race=neutralize_words(vocab_cleaned, vectors, word2idx_cleaned, race_dir)\n",
    "wv_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalize_words(wv_race, vocab_cleaned, word2idx_cleaned,\n",
    "               equalizing_lists['race'], race_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_race.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dict=get_debiased_dict(wv_gender, word2idx_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dict=get_debiased_dict(wv_race, word2idx_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2idx_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_gender= get_k_nearest_neighbors(random_words, gender_dict, list(gender_dict.keys()), wv_gender, word2idx_cleaned, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_race= get_k_nearest_neighbors(random_words, race_dict, list(race_dict.keys()), wv_race, word2idx_cleaned, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_gender[random_words[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_race[random_words[0]]==k_gender[random_words[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the first element of each tuple in the list k_race[random_words[0]]\n",
    "first_race=[k_race[random_words[0]][i][0] for i in range(len(k_race[random_words[0]]))]\n",
    "first_gender = [k_gender[random_words[0]][i][0]\n",
    "              for i in range(len(k_gender[random_words[0]]))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[first_race[i]==first_gender[i] for i in range(len(first_gender))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_freq = get_frequency_original_networks(\n",
    "    random_words, list_neigh, gender_dict, list(gender_dict.keys()), wv_gender, word2idx_cleaned, neighbours_num=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_freq = get_frequency_original_networks(\n",
    "    random_words, list_neigh, race_dict, list(race_dict.keys()), wv_race, word2idx_cleaned, neighbours_num=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_freq==race_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
