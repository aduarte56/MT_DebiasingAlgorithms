{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ProcessingEmbeddings import *\n",
    "from HardDebias import *\n",
    "from DoubleHardDebias import *\n",
    "from INLP import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove-wiki-gigaword-50 embeddings\n",
      "vectors shape: (400000, 50), word2idx length: 400000, vocab length: 400000\n"
     ]
    }
   ],
   "source": [
    "glove=Embeddings('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=glove.vectors\n",
    "word2idx=glove.word2idx\n",
    "vocab=glove.words\n",
    "dict_vectors = glove.get_word_vector_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(vectors).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender specific vocabulary:\n",
    "gender_specific=[]\n",
    "with open('./Data/male_word_file.txt') as f:\n",
    "    gender_specific = [line.strip() for line in f]\n",
    "\n",
    "with open('./Data/female_word_file.txt') as f:\n",
    "    for l in f:\n",
    "        gender_specific.append(l.strip())\n",
    "\n",
    "with codecs.open('./Data/gender_specific_full.json') as f:\n",
    "    gender_specific.extend(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Getting a limited vocabulary to debias the embeddings.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m vocab_cleaned, vectors_cleaned, word2idx_cleaned, dict_vec_cleaned \u001b[39m=\u001b[39m glove\u001b[39m.\u001b[39mlimit_vocab(vectors, word2idx, vocab, exclude\u001b[39m=\u001b[39mgender_specific)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glove' is not defined"
     ]
    }
   ],
   "source": [
    "# Getting a limited vocabulary to debias the embeddings.\n",
    "vocab_cleaned, vectors_cleaned, word2idx_cleaned, dict_vec_cleaned = glove.limit_vocab(vectors, word2idx, vocab, exclude=gender_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the definitional sets to calculate afterwards the gender direction. The first 10 gender sets were proposed by Bolukbasi et al. (2016)\n",
    "#Definitional sets for race where proposed by Manzini et al. in Multiclass debiasing of embeddings: https://github.com/TManzini/DebiasMulticlassWordEmbedding/blob/master/Debiasing/data/vocab/race_attributes_optm.json\n",
    "\n",
    "def_sets={\n",
    "    \"def_sets_gender\" : [\n",
    "    ['she', 'he'], ['herself', 'himself'], ['her', 'his'], ['daughter', 'son'], ['girl', 'boy'],\n",
    "    ['mother', 'father'], ['woman', 'man'], ['mary', 'john'], ['gal', 'guy'], ['female', 'male'],['aunt', 'uncle']],\n",
    "    \n",
    "    \"def_sets_race\":[\n",
    "\t\t[\"black\", \"caucasian\", \"asian\"],\n",
    "\t\t[\"african\", \"caucasian\", \"asian\"],\n",
    "\t\t[\"black\", \"white\", \"asian\"],\n",
    "\t\t[\"africa\", \"america\", \"asia\"],\n",
    "\t\t[\"africa\", \"america\", \"china\"],\n",
    "\t\t[\"africa\", \"europe\", \"asia\"]\n",
    "    ], \n",
    "    \"def_sets_religion\":[\n",
    "\t\t[\"judaism\", \"christianity\", \"islam\"],\n",
    "\t\t[\"jew\", \"christian\", \"muslim\"],\n",
    "    [\"synagogue\", \"church\", \"mosque\"],\n",
    "    [\"torah\", \"bible\", \"quran\"],\n",
    "    [\"rabbi\", \"priest\", \"imam\"]\n",
    "\t]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equalizing pairs were first published by Bolukbasi et al. in https://github.com/tolga-b/debiaswe/blob/master/data/equalize_pairs.json\n",
    "equalizing_list=[[\"monastery\", \"convent\"], [\"spokesman\", \"spokeswoman\"], [\"Catholic_priest\", \"nun\"], [\"Dad\", \"Mom\"], [\"Men\", \"Women\"], [\"councilman\", \"councilwoman\"], [\"grandpa\", \"grandma\"], [\"grandsons\", \"granddaughters\"], [\"prostate_cancer\", \"ovarian_cancer\"], [\"testosterone\", \"estrogen\"], [\"uncle\", \"aunt\"], [\"wives\", \"husbands\"], [\"Father\", \"Mother\"], [\"Grandpa\", \"Grandma\"], [\"He\", \"She\"], [\"boy\", \"girl\"], [\"boys\", \"girls\"], [\"brother\", \"sister\"], [\"brothers\", \"sisters\"], [\"businessman\", \"businesswoman\"], [\"chairman\", \"chairwoman\"], [\"colt\", \"filly\"], [\"congressman\", \"congresswoman\"], [\"dad\", \"mom\"], [\"dads\", \"moms\"], [\"dudes\", \"gals\"], [\"ex_girlfriend\", \"ex_boyfriend\"], [\"father\", \"mother\"], [\"fatherhood\", \"motherhood\"], [\"fathers\", \"mothers\"], [\"fella\", \"granny\"], [\"fraternity\", \"sorority\"], [\"gelding\", \"mare\"], [\"gentleman\", \"lady\"], [\"gentlemen\", \"ladies\"], [\"grandfather\", \"grandmother\"], [\"grandson\", \"granddaughter\"], [\"he\", \"she\"], [\"himself\", \"herself\"], [\"his\", \"her\"], [\"king\", \"queen\"], [\"kings\", \"queens\"], [\"male\", \"female\"], [\"males\", \"females\"], [\"man\", \"woman\"], [\"men\", \"women\"], [\"nephew\", \"niece\"], [\"prince\", \"princess\"], [\"schoolboy\", \"schoolgirl\"], [\"son\", \"daughter\"], [\"sons\", \"daughters\"], [\"twin_brother\", \"twin_sister\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard-Debias Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_vec_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m she_embed \u001b[39m=\u001b[39m dict_vectors[\u001b[39m'\u001b[39m\u001b[39mshe\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[39m# Using the gender bias function to compute the bias of all the words in the limited dataset\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m#We create a dictionary with the word as key and the bias as value\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m gender_bias_original \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mcompute_bias(dict_vec_cleaned, he_embed, she_embed)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dict_vec_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "# To compute the gender bias, we need to get the embeddings of \"he\" and \"she\"\n",
    "he_embed = dict_vectors['he']\n",
    "she_embed = dict_vectors['she']\n",
    "\n",
    "# Using the gender bias function to compute the bias of all the words in the limited dataset\n",
    "#We create a dictionary with the word as key and the bias as value\n",
    "gender_bias_original = utils.compute_bias(dict_vec_cleaned, he_embed, she_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_def_sets_subspace(list_def_sets):\n",
    "  def_sets={i: v for i, v in enumerate(list_def_sets)}\n",
    "  return def_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_set_gender=utils.prepare_def_sets_subspace(def_sets[\"def_sets_gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HardDebias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.418     0.24968  -0.41242  ... -0.18411  -0.11514  -0.78581 ]\n",
      " [ 0.013441  0.23682  -0.16899  ... -0.56657   0.044691  0.30392 ]\n",
      " [ 0.15164   0.30177  -0.16763  ... -0.35652   0.016413  0.10216 ]\n",
      " ...\n",
      " [-0.51181   0.058706  1.0913   ... -0.25003  -1.125     1.5863  ]\n",
      " [-0.75898  -0.47426   0.4737   ...  0.78954  -0.014116  0.6448  ]\n",
      " [ 0.072617 -0.51393   0.4728   ... -0.18907  -0.59021   0.55559 ]]\n",
      "number of words considered: 2\n",
      "Running PCA with 1 components\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (50,) and (1,50) not aligned: 50 (dim 0) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m debiased_vectors\u001b[39m=\u001b[39m HardDebias\u001b[39m.\u001b[39;49mhard_debias(vectors,\n\u001b[1;32m      2\u001b[0m                              dict_vec_cleaned, \n\u001b[1;32m      3\u001b[0m                              word2idx_cleaned,\n\u001b[1;32m      4\u001b[0m                              vocab_cleaned, \n\u001b[1;32m      5\u001b[0m                              equalizing_list, \n\u001b[1;32m      6\u001b[0m                              def_set_gender,\n\u001b[1;32m      7\u001b[0m                              \u001b[39m1\u001b[39;49m\n\u001b[1;32m      8\u001b[0m                              )\n",
      "File \u001b[0;32m~/Python/VersionControl/MT_DebiasingAlgorithms/HardDebias.py:148\u001b[0m, in \u001b[0;36mhard_debias\u001b[0;34m(wv, vector_dict_partial, w2i_partial, vocab_partial, equalizing_list, def_sets, subspace_dim, normalize)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(normalize)\u001b[39m.\u001b[39mlower()\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbefore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    145\u001b[0m   vectors\u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mnormalize(vectors) \u001b[39m#Following Andrew Ng's approach\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m wv_debiased\u001b[39m=\u001b[39mneutralize_words(vocab_partial, vectors, w2i_partial, bias_direction)\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(normalize)\u001b[39m.\u001b[39mlower()\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mafter\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    150\u001b[0m   wv_debiased\u001b[39m=\u001b[39mutils\u001b[39m.\u001b[39mnormalize(wv_debiased) \u001b[39m#Following Bolukbasi\u001b[39;00m\n",
      "File \u001b[0;32m~/Python/VersionControl/MT_DebiasingAlgorithms/HardDebias.py:93\u001b[0m, in \u001b[0;36mneutralize_words\u001b[0;34m(vocab_partial, vectors, w2i_partial, bias_direction)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mfor\u001b[39;00m i, words \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(vocab_partial):\n\u001b[1;32m     92\u001b[0m   u \u001b[39m=\u001b[39m vectors[w2i_partial[words], :]\n\u001b[0;32m---> 93\u001b[0m   u \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mremove_vector_projection(u, bias_direction)\n\u001b[1;32m     94\u001b[0m   debiased_vectors[w2i_partial[words], :] \u001b[39m=\u001b[39m u\n\u001b[1;32m     95\u001b[0m \u001b[39mreturn\u001b[39;00m debiased_vectors\n",
      "File \u001b[0;32m~/Python/VersionControl/MT_DebiasingAlgorithms/utils.py:60\u001b[0m, in \u001b[0;36mremove_vector_projection\u001b[0;34m(vector1, vector2)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mremove_vector_projection\u001b[39m(vector1, vector2):\n\u001b[0;32m---> 60\u001b[0m     projection\u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39;49mdot(vector1,vector2) \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(vector2))\u001b[39m*\u001b[39mvector2\n\u001b[1;32m     61\u001b[0m     difference \u001b[39m=\u001b[39m vector1 \u001b[39m-\u001b[39m projection\n\u001b[1;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m difference\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (50,) and (1,50) not aligned: 50 (dim 0) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "debiased_vectors= HardDebias.hard_debias(vectors,\n",
    "                             dict_vec_cleaned, \n",
    "                             word2idx_cleaned,\n",
    "                             vocab_cleaned, \n",
    "                             equalizing_list, \n",
    "                             def_set_gender,\n",
    "                             1\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiased_vocab_limited, debiased_vectors_limited, debiased_word2idx_limited = glove.limit_vocab(debiased_vectors, word2idx, vocab, exclude = gender_specific)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Double-Hard Debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_w2i, biased_vocab, female_words, male_words, y_true=utils.getting_biased_words(gender_bias_original, def_sets[\"def_sets_gender\"], 1000,word2idx_cleaned)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.isnan(vectors).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, optimal_direction = getting_optimal_direction(vectors, word2idx, biased_w2i, biased_vocab, male_words, female_words, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_debiased_vectors= DoubleHardDebias.hard_debias(vectors, word2idx, word2idx, vocab, [optimal_direction], gendered_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_debiased_vocab_limited, dh_debiased_vectors_limited, dh_debiased_word2idx_limited = glove.limit_vocab(dh_debiased_vectors, word2idx, vocab, exclude = gender_specific)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_vectors_per_class = 7500\n",
    "\n",
    "#gender_direction=algorithm1.find_gender_direction(vectors, word2idx_cleaned)\n",
    "\n",
    "gender_vecs = [glove.model[p[0]] - glove.model[p[1]] for p in gendered_pairs]\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(gender_vecs)\n",
    "gender_direction = pca.components_[0]\n",
    "\n",
    "gender_unit_vec = gender_direction/np.linalg.norm(gender_direction)\n",
    "masc_words_and_scores, fem_words_and_scores, neut_words_and_scores = getting_classes_for_INLP(gender_vector=gender_direction, model=glove.model, n = 7500)\n",
    "\n",
    "masc_words, masc_scores = list(zip(*masc_words_and_scores))\n",
    "neut_words, neut_scores = list(zip(*neut_words_and_scores))\n",
    "fem_words, fem_scores = list(zip(*fem_words_and_scores))\n",
    "masc_vecs, fem_vecs = glove.get_vectors_from_list(masc_words), glove.get_vectors_from_list(fem_words)\n",
    "neut_vecs = glove.get_vectors_from_list(neut_words)\n",
    "\n",
    "n = min(3000, num_vectors_per_class)\n",
    "all_significantly_biased_words = masc_words[:n] + fem_words[:n]\n",
    "all_significantly_biased_vecs =  np.concatenate((masc_vecs[:n], fem_vecs[:n]))\n",
    "all_significantly_biased_labels = np.concatenate((np.ones(n, dtype = int),\n",
    "                                                  np.zeros(n, dtype = int)))\n",
    "\n",
    "all_significantly_biased_words, all_significantly_biased_vecs, all_significantly_biased_labels = sklearn.utils.shuffle(\n",
    "all_significantly_biased_words, all_significantly_biased_vecs, all_significantly_biased_labels)\n",
    "#print(np.random.choice(masc_words, size = 75))\n",
    "print(\"TOP MASC:\",masc_words[:50] )\n",
    "print(\"-------------------------\")\n",
    "print(\"TOP FEM:\", fem_words[:50])\n",
    "print(\"-------------------------\")\n",
    "print(\"Random Neutral:\", neut_words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.concatenate((masc_vecs, fem_vecs, neut_vecs), axis = 0)\n",
    "#X = (X - np.mean(X, axis = 0, keepdims = True)) / np.std(X, axis = 0)\n",
    "y_masc = np.ones(masc_vecs.shape[0], dtype = int)\n",
    "y_fem = np.zeros(fem_vecs.shape[0], dtype = int)\n",
    "y_neut = -np.ones(neut_vecs.shape[0], dtype = int)\n",
    "#y = np.concatenate((masc_scores, fem_scores, neut_scores))#np.concatenate((y_masc, y_fem))\n",
    "y = np.concatenate((y_masc, y_fem, y_neut))\n",
    "X_train_dev, X_test, y_train_dev, Y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "X_train, X_dev, Y_train, Y_dev = sklearn.model_selection.train_test_split(X_train_dev, y_train_dev, test_size = 0.3, random_state = 0)\n",
    "print(\"Train size: {}; Dev size: {}; Test size: {}\".format(X_train.shape[0], X_dev.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_clf = LinearSVC\n",
    "#gender_clf = SGDClassifier\n",
    "#gender_clf = LogisticRegression\n",
    "#gender_clf = LinearDiscriminantAnalysis\n",
    "#gender_clf = Perceptron\n",
    "\n",
    "params_svc = {'penalty': 'l2','fit_intercept': False, 'class_weight': None, \"dual\": False, 'random_state': 0}\n",
    "params_sgd = {'penalty': 'l2','fit_intercept': False, 'class_weight': None, 'max_iter': 1000, 'random_state': 0}\n",
    "params = params_svc\n",
    "#params = {'loss': 'hinge', 'n_jobs': 16, 'penalty': 'l2', 'max_iter': 2500, 'random_state': 0}\n",
    "#params = {}\n",
    "n = 35\n",
    "min_acc = 0\n",
    "dropout_rate = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P, rowspace_projs, Ws = INLP.get_debiasing_projection(gender_clf, params, n, 50, min_acc,\n",
    "                                    X_train, Y_train, X_dev, Y_dev, Y_train_main=None, Y_dev_main=None, \n",
    "                                       dropout_rate = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
